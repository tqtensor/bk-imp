@misc{abid2021persistent,
  title         = {Persistent Anti-Muslim Bias in Large Language Models},
  author        = {Abubakar Abid and Maheen Farooqi and James Zou},
  year          = {2021},
  eprint        = {2101.05783},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@inproceedings{akyurek-etal-2023-rl4f,
  title     = {{RL}4{F}: Generating Natural Language Feedback with Reinforcement Learning for Repairing Model Outputs},
  author    = {Akyurek, Afra Feyza  and
               Akyurek, Ekin  and
               Kalyan, Ashwin  and
               Clark, Peter  and
               Wijaya, Derry Tanti  and
               Tandon, Niket},
  editor    = {Rogers, Anna  and
               Boyd-Graber, Jordan  and
               Okazaki, Naoaki},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = jul,
  year      = {2023},
  address   = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.acl-long.427},
  doi       = {10.18653/v1/2023.acl-long.427},
  pages     = {7716--7733},
  abstract  = {Despite their unprecedented success, even the largest language models make mistakes. Similar to how humans learn and improve using feedback, previous work proposed providing language models with natural language feedback to guide them in repairing their outputs. Because human-generated critiques are expensive to obtain, researchers have devised learned critique generators in lieu of human critics while assuming one can train downstream models to utilize generated feedback. However, this approach does not apply to black-box or limited access models such as ChatGPT, as they cannot be fine-tuned. Moreover, in the era of large general-purpose language agents, fine-tuning is neither computationally nor spatially efficient as it results in multiple copies of the network. In this work, we introduce RL4F (Reinforcement Learning for Feedback), a multi-agent collaborative framework where the critique generator is trained to maximize end-task performance of GPT-3, a fixed model more than 200 times its size. RL4F produces critiques that help GPT-3 revise its outputs. We study three datasets for action planning, summarization and alphabetization and show relative improvements up to 10{\%} in multiple text similarity metrics over other learned, retrieval-augmented or prompting-based critique generators.}
}
@article{askell2021general,
  title   = {A general language assistant as a laboratory for alignment},
  author  = {Askell, Amanda and Bai, Yuntao and Chen, Anna and Drain, Dawn and Ganguli, Deep and Henighan, Tom and Jones, Andy and Joseph, Nicholas and Mann, Ben and DasSarma, Nova and others},
  journal = {arXiv preprint arXiv:2112.00861},
  year    = {2021}
}
@article{baevski2018adaptive,
  title   = {Adaptive input representations for neural language modeling},
  author  = {Baevski, Alexei and Auli, Michael},
  journal = {arXiv preprint arXiv:1809.10853},
  year    = {2018}
}
@article{bahdanau2014neural,
  title   = {Neural machine translation by jointly learning to align and translate},
  author  = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal = {arXiv preprint arXiv:1409.0473},
  year    = {2014}
}
@misc{bai2022constitutional,
  title         = {Constitutional AI: Harmlessness from AI Feedback},
  author        = {Yuntao Bai and Saurav Kadavath and Sandipan Kundu and Amanda Askell and Jackson Kernion and Andy Jones and Anna Chen and Anna Goldie and Azalia Mirhoseini and Cameron McKinnon and Carol Chen and Catherine Olsson and Christopher Olah and Danny Hernandez and Dawn Drain and Deep Ganguli and Dustin Li and Eli Tran-Johnson and Ethan Perez and Jamie Kerr and Jared Mueller and Jeffrey Ladish and Joshua Landau and Kamal Ndousse and Kamile Lukosuite and Liane Lovitt and Michael Sellitto and Nelson Elhage and Nicholas Schiefer and Noemi Mercado and Nova DasSarma and Robert Lasenby and Robin Larson and Sam Ringer and Scott Johnston and Shauna Kravec and Sheer El Showk and Stanislav Fort and Tamera Lanham and Timothy Telleen-Lawton and Tom Conerly and Tom Henighan and Tristan Hume and Samuel R. Bowman and Zac Hatfield-Dodds and Ben Mann and Dario Amodei and Nicholas Joseph and Sam McCandlish and Tom Brown and Jared Kaplan},
  year          = {2022},
  eprint        = {2212.08073},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{bai2022training,
  title         = {Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback},
  author        = {Yuntao Bai and Andy Jones and Kamal Ndousse and Amanda Askell and Anna Chen and Nova DasSarma and Dawn Drain and Stanislav Fort and Deep Ganguli and Tom Henighan and Nicholas Joseph and Saurav Kadavath and Jackson Kernion and Tom Conerly and Sheer El-Showk and Nelson Elhage and Zac Hatfield-Dodds and Danny Hernandez and Tristan Hume and Scott Johnston and Shauna Kravec and Liane Lovitt and Neel Nanda and Catherine Olsson and Dario Amodei and Tom Brown and Jack Clark and Sam McCandlish and Chris Olah and Ben Mann and Jared Kaplan},
  year          = {2022},
  eprint        = {2204.05862},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{brown2020language,
  title         = {Language Models are Few-Shot Learners},
  author        = {Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  year          = {2020},
  eprint        = {2005.14165},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{chang2023learning,
  title         = {Learning to Generate Better Than Your LLM},
  author        = {Jonathan D. Chang and Kiante Brantley and Rajkumar Ramamurthy and Dipendra Misra and Wen Sun},
  year          = {2023},
  eprint        = {2306.11816},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@misc{charalambous2023new,
  title         = {A New Era in Software Security: Towards Self-Healing Software via Large Language Models and Formal Verification},
  author        = {Yiannis Charalambous and Norbert Tihanyi and Ridhi Jain and Youcheng Sun and Mohamed Amine Ferrag and Lucas C. Cordeiro},
  year          = {2023},
  eprint        = {2305.14752},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}
@misc{chen2021evaluating,
  title         = {Evaluating Large Language Models Trained on Code},
  author        = {Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
  year          = {2021},
  eprint        = {2107.03374},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@misc{chen2022codet,
  title         = {CodeT: Code Generation with Generated Tests},
  author        = {Bei Chen and Fengji Zhang and Anh Nguyen and Daoguang Zan and Zeqi Lin and Jian-Guang Lou and Weizhu Chen},
  year          = {2022},
  eprint        = {2207.10397},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{chen2023improving,
  title         = {Improving Code Generation by Training with Natural Language Feedback},
  author        = {Angelica Chen and Jérémy Scheurer and Tomasz Korbak and Jon Ander Campos and Jun Shern Chan and Samuel R. Bowman and Kyunghyun Cho and Ethan Perez},
  year          = {2023},
  eprint        = {2303.16749},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}
@misc{chen2023teaching,
  title         = {Teaching Large Language Models to Self-Debug},
  author        = {Xinyun Chen and Maxwell Lin and Nathanael Schärli and Denny Zhou},
  year          = {2023},
  eprint        = {2304.05128},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{chern2023factool,
  title         = {FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios},
  author        = {I-Chun Chern and Steffi Chern and Shiqi Chen and Weizhe Yuan and Kehua Feng and Chunting Zhou and Junxian He and Graham Neubig and Pengfei Liu},
  year          = {2023},
  eprint        = {2307.13528},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@article{child2019generating,
  title   = {Generating long sequences with sparse transformers},
  author  = {Child, Rewon and Gray, Scott and Radford, Alec and Sutskever, Ilya},
  journal = {arXiv preprint arXiv:1904.10509},
  year    = {2019}
}
@article{chowdhery2023palm,
  title   = {Palm: Scaling language modeling with pathways},
  author  = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal = {Journal of Machine Learning Research},
  volume  = {24},
  number  = {240},
  pages   = {1--113},
  year    = {2023}
}
@article{chung2022scaling,
  title   = {Scaling instruction-finetuned language models},
  author  = {Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Eric and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal = {arXiv preprint arXiv:2210.11416},
  year    = {2022}
}
@misc{clark2021thats,
  title         = {All That's 'Human' Is Not Gold: Evaluating Human Evaluation of Generated Text},
  author        = {Elizabeth Clark and Tal August and Sofia Serrano and Nikita Haduong and Suchin Gururangan and Noah A. Smith},
  year          = {2021},
  eprint        = {2107.00061},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{cobbe2021training,
  title         = {Training Verifiers to Solve Math Word Problems},
  author        = {Karl Cobbe and Vineet Kosaraju and Mohammad Bavarian and Mark Chen and Heewoo Jun and Lukasz Kaiser and Matthias Plappert and Jerry Tworek and Jacob Hilton and Reiichiro Nakano and Christopher Hesse and John Schulman},
  year          = {2021},
  eprint        = {2110.14168},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@misc{cohen2023lm,
  title         = {LM vs LM: Detecting Factual Errors via Cross Examination},
  author        = {Roi Cohen and May Hamri and Mor Geva and Amir Globerson},
  year          = {2023},
  eprint        = {2305.13281},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{creswell2022faithful,
  title         = {Faithful Reasoning Using Large Language Models},
  author        = {Antonia Creswell and Murray Shanahan},
  year          = {2022},
  eprint        = {2208.14271},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI}
}
@article{dao2022flashattention,
  title   = {Flashattention: Fast and memory-efficient exact attention with io-awareness},
  author  = {Dao, Tri and Fu, Dan and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {35},
  pages   = {16344--16359},
  year    = {2022}
}
@misc{dathathri2020plug,
  title         = {Plug and Play Language Models: A Simple Approach to Controlled Text Generation},
  author        = {Sumanth Dathathri and Andrea Madotto and Janice Lan and Jane Hung and Eric Frank and Piero Molino and Jason Yosinski and Rosanne Liu},
  year          = {2020},
  eprint        = {1912.02164},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@inproceedings{dauphin2017language,
  title        = {Language modeling with gated convolutional networks},
  author       = {Dauphin, Yann N and Fan, Angela and Auli, Michael and Grangier, David},
  booktitle    = {International conference on machine learning},
  pages        = {933--941},
  year         = {2017},
  organization = {PMLR}
}
@misc{devlin2019bert,
  title         = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author        = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  year          = {2019},
  eprint        = {1810.04805},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@article{dong2022survey,
  title   = {A survey for in-context learning},
  author  = {Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Wu, Zhiyong and Chang, Baobao and Sun, Xu and Xu, Jingjing and Sui, Zhifang},
  journal = {arXiv preprint arXiv:2301.00234},
  year    = {2022}
}
@misc{du2023improving,
  title         = {Improving Factuality and Reasoning in Language Models through Multiagent Debate},
  author        = {Yilun Du and Shuang Li and Antonio Torralba and Joshua B. Tenenbaum and Igor Mordatch},
  year          = {2023},
  eprint        = {2305.14325},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{dubois2024alpacafarm,
  title         = {AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback},
  author        = {Yann Dubois and Xuechen Li and Rohan Taori and Tianyi Zhang and Ishaan Gulrajani and Jimmy Ba and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto},
  year          = {2024},
  eprint        = {2305.14387},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@article{eriksen1972some,
  title     = {Some characteristics of selective attention in visual perception determined by vocal reaction time},
  author    = {Eriksen, Charles W and Hoffman, James E},
  journal   = {Perception \& Psychophysics},
  volume    = {11},
  number    = {2},
  pages     = {169--171},
  year      = {1972},
  publisher = {Springer}
}
@misc{fernandes2023bridging,
  title         = {Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation},
  author        = {Patrick Fernandes and Aman Madaan and Emmy Liu and António Farinhas and Pedro Henrique Martins and Amanda Bertsch and José G. C. de Souza and Shuyan Zhou and Tongshuang Wu and Graham Neubig and André F. T. Martins},
  year          = {2023},
  eprint        = {2305.00955},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{first2023baldur,
  title         = {Baldur: Whole-Proof Generation and Repair with Large Language Models},
  author        = {Emily First and Markus N. Rabe and Talia Ringer and Yuriy Brun},
  year          = {2023},
  eprint        = {2303.04910},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@article{freitag-etal-2022-high,
  title     = {High Quality Rather than High Model Probability: Minimum {B}ayes Risk Decoding with Neural Metrics},
  author    = {Freitag, Markus  and
               Grangier, David  and
               Tan, Qijun  and
               Liang, Bowen},
  editor    = {Roark, Brian  and
               Nenkova, Ani},
  journal   = {Transactions of the Association for Computational Linguistics},
  volume    = {10},
  year      = {2022},
  address   = {Cambridge, MA},
  publisher = {MIT Press},
  url       = {https://aclanthology.org/2022.tacl-1.47},
  doi       = {10.1162/tacl_a_00491},
  pages     = {811--825},
  abstract  = {In Neural Machine Translation, it is typically assumed that the sentence with the highest estimated probability should also be the translation with the highest quality as measured by humans. In this work, we question this assumption and show that model estimates and translation quality only vaguely correlate. We apply Minimum Bayes Risk (MBR) decoding on unbiased samples to optimize diverse automated metrics of translation quality as an alternative inference strategy to beam search. Instead of targeting the hypotheses with the highest model probability, MBR decoding extracts the hypotheses with the highest estimated quality. Our experiments show that the combination of a neural translation model with a neural reference-based metric, Bleurt, results in significant improvement in human evaluations. This improvement is obtained with translations different from classical beam-search output: These translations have much lower model likelihood and are less favored by surface metrics like Bleu.}
}
@misc{fu2023improving,
  title         = {Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback},
  author        = {Yao Fu and Hao Peng and Tushar Khot and Mirella Lapata},
  year          = {2023},
  eprint        = {2305.10142},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{ganguli2023capacity,
  title         = {The Capacity for Moral Self-Correction in Large Language Models},
  author        = {Deep Ganguli and Amanda Askell and Nicholas Schiefer and Thomas I. Liao and Kamilė Lukošiūtė and Anna Chen and Anna Goldie and Azalia Mirhoseini and Catherine Olsson and Danny Hernandez and Dawn Drain and Dustin Li and Eli Tran-Johnson and Ethan Perez and Jackson Kernion and Jamie Kerr and Jared Mueller and Joshua Landau and Kamal Ndousse and Karina Nguyen and Liane Lovitt and Michael Sellitto and Nelson Elhage and Noemi Mercado and Nova DasSarma and Oliver Rausch and Robert Lasenby and Robin Larson and Sam Ringer and Sandipan Kundu and Saurav Kadavath and Scott Johnston and Shauna Kravec and Sheer El Showk and Tamera Lanham and Timothy Telleen-Lawton and Tom Henighan and Tristan Hume and Yuntao Bai and Zac Hatfield-Dodds and Ben Mann and Dario Amodei and Nicholas Joseph and Sam McCandlish and Tom Brown and Christopher Olah and Jack Clark and Samuel R. Bowman and Jared Kaplan},
  year          = {2023},
  eprint        = {2302.07459},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{gao2023continually,
  title         = {Continually Improving Extractive QA via Human Feedback},
  author        = {Ge Gao and Hung-Ting Chen and Yoav Artzi and Eunsol Choi},
  year          = {2023},
  eprint        = {2305.12473},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{gao2023rarr,
  title         = {RARR: Researching and Revising What Language Models Say, Using Language Models},
  author        = {Luyu Gao and Zhuyun Dai and Panupong Pasupat and Anthony Chen and Arun Tejasvi Chaganty and Yicheng Fan and Vincent Y. Zhao and Ni Lao and Hongrae Lee and Da-Cheng Juan and Kelvin Guu},
  year          = {2023},
  eprint        = {2210.08726},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{gero2023selfverification,
  title         = {Self-Verification Improves Few-Shot Clinical Information Extraction},
  author        = {Zelalem Gero and Chandan Singh and Hao Cheng and Tristan Naumann and Michel Galley and Jianfeng Gao and Hoifung Poon},
  year          = {2023},
  eprint        = {2306.00024},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{glaese2022improving,
  title         = {Improving alignment of dialogue agents via targeted human judgements},
  author        = {Amelia Glaese and Nat McAleese and Maja Trebacz and John Aslanides and Vlad Firoiu and Timo Ewalds and Maribeth Rauh and Laura Weidinger and Martin Chadwick and Phoebe Thacker and Lucy Campbell-Gillingham and Jonathan Uesato and Po-Sen Huang and Ramona Comanescu and Fan Yang and Abigail See and Sumanth Dathathri and Rory Greig and Charlie Chen and Doug Fritz and Jaume Sanchez Elias and Richard Green and Sona Mokra and Nicholas Fernando and Boxi Wu and Rachel Foley and Susannah Young and Iason Gabriel and William Isaac and John Mellor and Demis Hassabis and Koray Kavukcuoglu and Lisa Anne Hendricks and Geoffrey Irving},
  year          = {2022},
  eprint        = {2209.14375},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@misc{goldstein2023generative,
  title         = {Generative Language Models and Automated Influence Operations: Emerging Threats and Potential Mitigations},
  author        = {Josh A. Goldstein and Girish Sastry and Micah Musser and Renee DiResta and Matthew Gentzel and Katerina Sedova},
  year          = {2023},
  eprint        = {2301.04246},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CY}
}
@misc{golovneva2023roscoe,
  title         = {ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning},
  author        = {Olga Golovneva and Moya Chen and Spencer Poff and Martin Corredor and Luke Zettlemoyer and Maryam Fazel-Zarandi and Asli Celikyilmaz},
  year          = {2023},
  eprint        = {2212.07919},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{gou2023critic,
  title         = {CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing},
  author        = {Zhibin Gou and Zhihong Shao and Yeyun Gong and Yelong Shen and Yujiu Yang and Nan Duan and Weizhu Chen},
  year          = {2023},
  eprint        = {2305.11738},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{gulcehre2023reinforced,
  title         = {Reinforced Self-Training (ReST) for Language Modeling},
  author        = {Caglar Gulcehre and Tom Le Paine and Srivatsan Srinivasan and Ksenia Konyushkova and Lotte Weerts and Abhishek Sharma and Aditya Siddhant and Alex Ahern and Miaosen Wang and Chenjie Gu and Wolfgang Macherey and Arnaud Doucet and Orhan Firat and Nando de Freitas},
  year          = {2023},
  eprint        = {2308.08998},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{hao2023reasoning,
  title         = {Reasoning with Language Model is Planning with World Model},
  author        = {Shibo Hao and Yi Gu and Haodi Ma and Joshua Jiahua Hong and Zhen Wang and Daisy Zhe Wang and Zhiting Hu},
  year          = {2023},
  eprint        = {2305.14992},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{he2021deberta,
  title         = {DeBERTa: Decoding-enhanced BERT with Disentangled Attention},
  author        = {Pengcheng He and Xiaodong Liu and Jianfeng Gao and Weizhu Chen},
  year          = {2021},
  eprint        = {2006.03654},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{he2022rethinking,
  title         = {Rethinking with Retrieval: Faithful Large Language Model Inference},
  author        = {Hangfeng He and Hongming Zhang and Dan Roth},
  year          = {2022},
  eprint        = {2301.00303},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@article{hendrycks2016gaussian,
  title   = {Gaussian error linear units (gelus)},
  author  = {Hendrycks, Dan and Gimpel, Kevin},
  journal = {arXiv preprint arXiv:1606.08415},
  year    = {2016}
}
@misc{hendrycks2021measuring,
  title         = {Measuring Coding Challenge Competence With APPS},
  author        = {Dan Hendrycks and Steven Basart and Saurav Kadavath and Mantas Mazeika and Akul Arora and Ethan Guo and Collin Burns and Samir Puranik and Horace He and Dawn Song and Jacob Steinhardt},
  year          = {2021},
  eprint        = {2105.09938},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}
@misc{hernandez2021scaling,
  title         = {Scaling Laws for Transfer},
  author        = {Danny Hernandez and Jared Kaplan and Tom Henighan and Sam McCandlish},
  year          = {2021},
  eprint        = {2102.01293},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@article{hornik1989multilayer,
  title     = {Multilayer feedforward networks are universal approximators},
  author    = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  journal   = {Neural networks},
  volume    = {2},
  number    = {5},
  pages     = {359--366},
  year      = {1989},
  publisher = {Elsevier}
}
@misc{huang2022large,
  title         = {Large Language Models Can Self-Improve},
  author        = {Jiaxin Huang and Shixiang Shane Gu and Le Hou and Yuexin Wu and Xuezhi Wang and Hongkun Yu and Jiawei Han},
  year          = {2022},
  eprint        = {2210.11610},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@article{huang2022towards,
  title   = {Towards reasoning in large language models: A survey},
  author  = {Huang, Jie and Chang, Kevin Chen-Chuan},
  journal = {arXiv preprint arXiv:2212.10403},
  year    = {2022}
}
@article{iyer2022opt,
  title   = {Opt-iml: Scaling language model instruction meta learning through the lens of generalization},
  author  = {Iyer, Srinivasan and Lin, Xi Victoria and Pasunuru, Ramakanth and Mihaylov, Todor and Simig, Daniel and Yu, Ping and Shuster, Kurt and Wang, Tianlu and Liu, Qing and Koura, Punit Singh and others},
  journal = {arXiv preprint arXiv:2212.12017},
  year    = {2022}
}
@misc{jang2017categorical,
  title         = {Categorical Reparameterization with Gumbel-Softmax},
  author        = {Eric Jang and Shixiang Gu and Ben Poole},
  year          = {2017},
  eprint        = {1611.01144},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ML}
}
@inproceedings{jauregi-unanue-etal-2021-berttune,
  title     = {{BERTT}une: Fine-Tuning Neural Machine Translation with {BERTS}core},
  author    = {Jauregi Unanue, Inigo  and
               Parnell, Jacob  and
               Piccardi, Massimo},
  editor    = {Zong, Chengqing  and
               Xia, Fei  and
               Li, Wenjie  and
               Navigli, Roberto},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)},
  month     = aug,
  year      = {2021},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.acl-short.115},
  doi       = {10.18653/v1/2021.acl-short.115},
  pages     = {915--924},
  abstract  = {Neural machine translation models are often biased toward the limited translation references seen during training. To amend this form of overfitting, in this paper we propose fine-tuning the models with a novel training objective based on the recently-proposed BERTScore evaluation metric. BERTScore is a scoring function based on contextual embeddings that overcomes the typical limitations of n-gram-based metrics (e.g. synonyms, paraphrases), allowing translations that are different from the references, yet close in the contextual embedding space, to be treated as substantially correct. To be able to use BERTScore as a training objective, we propose three approaches for generating soft predictions, allowing the network to remain completely differentiable end-to-end. Experiments carried out over four, diverse language pairs show improvements of up to 0.58 pp (3.28{\%}) in BLEU score and up to 0.76 pp (0.98{\%}) in BERTScore (F{\_}BERT) when fine-tuning a strong baseline.}
}
@inproceedings{jung-etal-2022-maieutic,
  title     = {Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations},
  author    = {Jung, Jaehun  and
               Qin, Lianhui  and
               Welleck, Sean  and
               Brahman, Faeze  and
               Bhagavatula, Chandra  and
               Le Bras, Ronan  and
               Choi, Yejin},
  editor    = {Goldberg, Yoav  and
               Kozareva, Zornitsa  and
               Zhang, Yue},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  month     = dec,
  year      = {2022},
  address   = {Abu Dhabi, United Arab Emirates},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2022.emnlp-main.82},
  doi       = {10.18653/v1/2022.emnlp-main.82},
  pages     = {1266--1279},
  abstract  = {Pre-trained language models (LMs) struggle with consistent reasoning; recently, prompting LMs to generate explanations that self-guide the inference has emerged as a promising direction to amend this. However, these approaches are fundamentally bounded by the correctness of explanations, which themselves are often noisy and inconsistent. In this work, we develop Maieutic Prompting, which aims to infer a correct answer to a question even from the unreliable generations of LM. Maieutic Prompting induces a tree of explanations abductively (e.g. X is true, because ...) and recursively, then frames the inference as a satisfiability problem over these explanations and their logical relations. We test Maieutic Prompting for true/false QA on three challenging benchmarks that require complex commonsense reasoning. Maieutic Prompting achieves up to 20{\%} better accuracy than state-of-the-art prompting methods, and as a fully unsupervised approach, performs competitively with supervised models. We also show that Maieutic Prompting improves robustness in inference while providing interpretable rationales.}
}
@misc{kaplan2020scaling,
  title         = {Scaling Laws for Neural Language Models},
  author        = {Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei},
  year          = {2020},
  eprint        = {2001.08361},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@misc{kenton2021alignment,
  title         = {Alignment of Language Agents},
  author        = {Zachary Kenton and Tom Everitt and Laura Weidinger and Iason Gabriel and Vladimir Mikulik and Geoffrey Irving},
  year          = {2021},
  eprint        = {2103.14659},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI}
}
@misc{keskar2019ctrl,
  title         = {CTRL: A Conditional Transformer Language Model for Controllable Generation},
  author        = {Nitish Shirish Keskar and Bryan McCann and Lav R. Varshney and Caiming Xiong and Richard Socher},
  year          = {2019},
  eprint        = {1909.05858},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{khalifa2023grace,
  title         = {GRACE: Discriminator-Guided Chain-of-Thought Reasoning},
  author        = {Muhammad Khalifa and Lajanugen Logeswaran and Moontae Lee and Honglak Lee and Lu Wang},
  year          = {2023},
  eprint        = {2305.14934},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{khlaaf2022hazard,
  title         = {A Hazard Analysis Framework for Code Synthesis Large Language Models},
  author        = {Heidy Khlaaf and Pamela Mishkin and Joshua Achiam and Gretchen Krueger and Miles Brundage},
  year          = {2022},
  eprint        = {2207.14157},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}
@article{kim2023cot,
  title   = {The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning},
  author  = {Kim, Seungone and Joo, Se June and Kim, Doyoung and Jang, Joel and Ye, Seonghyeon and Shin, Jamin and Seo, Minjoon},
  journal = {arXiv preprint arXiv:2305.14045},
  year    = {2023}
}
@misc{korbak2023pretraining,
  title         = {Pretraining Language Models with Human Preferences},
  author        = {Tomasz Korbak and Kejian Shi and Angelica Chen and Rasika Bhalerao and Christopher L. Buckley and Jason Phang and Samuel R. Bowman and Ethan Perez},
  year          = {2023},
  eprint        = {2302.08582},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@article{krueger2016zoneout,
  title   = {Zoneout: Regularizing rnns by randomly preserving hidden activations},
  author  = {Krueger, David and Maharaj, Tegan and Kram{\'a}r, J{\'a}nos and Pezeshki, Mohammad and Ballas, Nicolas and Ke, Nan Rosemary and Goyal, Anirudh and Bengio, Yoshua and Courville, Aaron and Pal, Chris},
  journal = {arXiv preprint arXiv:1606.01305},
  year    = {2016}
}
@article{kudo2018subword,
  title   = {Subword regularization: Improving neural network translation models with multiple subword candidates},
  author  = {Kudo, Taku},
  journal = {arXiv preprint arXiv:1804.10959},
  year    = {2018}
}
@misc{le2022coderl,
  title         = {CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning},
  author        = {Hung Le and Yue Wang and Akhilesh Deepak Gotmare and Silvio Savarese and Steven C. H. Hoi},
  year          = {2022},
  eprint        = {2207.01780},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@misc{le2023codechain,
  title         = {CodeChain: Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules},
  author        = {Hung Le and Hailin Chen and Amrita Saha and Akash Gokul and Doyen Sahoo and Shafiq Joty},
  year          = {2023},
  eprint        = {2310.08992},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI}
}
@article{Li_2022,
  title     = {Competition-level code generation with AlphaCode},
  volume    = {378},
  issn      = {1095-9203},
  url       = {http://dx.doi.org/10.1126/science.abq1158},
  doi       = {10.1126/science.abq1158},
  number    = {6624},
  journal   = {Science},
  publisher = {American Association for the Advancement of Science (AAAS)},
  author    = {Li, Yujia and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, Rémi and Eccles, Tom and Keeling, James and Gimeno, Felix and Dal Lago, Agustin and Hubert, Thomas and Choy, Peter and de Masson d’Autume, Cyprien and Babuschkin, Igor and Chen, Xinyun and Huang, Po-Sen and Welbl, Johannes and Gowal, Sven and Cherepanov, Alexey and Molloy, James and Mankowitz, Daniel J. and Sutherland Robson, Esme and Kohli, Pushmeet and de Freitas, Nando and Kavukcuoglu, Koray and Vinyals, Oriol},
  year      = {2022},
  month     = dec,
  pages     = {1092–1097}
}
@inproceedings{li-etal-2019-deep,
  title     = {Deep Reinforcement Learning with Distributional Semantic Rewards for Abstractive Summarization},
  author    = {Li, Siyao  and
               Lei, Deren  and
               Qin, Pengda  and
               Wang, William Yang},
  editor    = {Inui, Kentaro  and
               Jiang, Jing  and
               Ng, Vincent  and
               Wan, Xiaojun},
  booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  month     = nov,
  year      = {2019},
  address   = {Hong Kong, China},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/D19-1623},
  doi       = {10.18653/v1/D19-1623},
  pages     = {6038--6044},
  abstract  = {Deep reinforcement learning (RL) has been a commonly-used strategy for the abstractive summarization task to address both the exposure bias and non-differentiable task issues. However, the conventional reward Rouge-L simply looks for exact n-grams matches between candidates and annotated references, which inevitably makes the generated sentences repetitive and incoherent. In this paper, instead of Rouge-L, we explore the practicability of utilizing the distributional semantics to measure the matching degrees. With distributional semantics, sentence-level evaluation can be obtained, and semantically-correct phrases can also be generated without being limited to the surface form of the reference sentences. Human judgments on Gigaword and CNN/Daily Mail datasets show that our proposed distributional semantics reward (DSR) has distinct superiority in capturing the lexical and compositional diversity of natural language.}
}
@inproceedings{li-etal-2023-making,
  title     = {Making Language Models Better Reasoners with Step-Aware Verifier},
  author    = {Li, Yifei  and
               Lin, Zeqi  and
               Zhang, Shizhuo  and
               Fu, Qiang  and
               Chen, Bei  and
               Lou, Jian-Guang  and
               Chen, Weizhu},
  editor    = {Rogers, Anna  and
               Boyd-Graber, Jordan  and
               Okazaki, Naoaki},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = jul,
  year      = {2023},
  address   = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.acl-long.291},
  doi       = {10.18653/v1/2023.acl-long.291},
  pages     = {5315--5333},
  abstract  = {Few-shot learning is a challenging task that requires language models to generalize from limited examples. Large language models like GPT-3 and PaLM have made impressive progress in this area, but they still face difficulties in reasoning tasks such as GSM8K, a benchmark for arithmetic problems. To improve their reasoning skills, previous work has proposed to guide the language model with prompts that elicit a series of reasoning steps before giving the final answer, achieving a significant improvement on GSM8K from 17.9{\%} to 58.1{\%} in problem-solving rate. In this paper, we present DiVeRSe (Diverse Verifier on Reasoning Step), a novel approach that further enhances the reasoning capability of language models. DiVeRSe has three main components: first, it generates diverse prompts to explore different reasoning paths for the same question; second, it uses a verifier to filter out incorrect answers based on a weighted voting scheme; and third, it verifies each reasoning step individually instead of the whole chain. We evaluate DiVeRSe on the latest language model code-davinci-002 and show that it achieves new state-of-the-art results on six of eight reasoning benchmarks (e.g., GSM8K 74.4{\%} to 83.2{\%}).}
}
@misc{li2022diffusionlm,
  title         = {Diffusion-LM Improves Controllable Text Generation},
  author        = {Xiang Lisa Li and John Thickstun and Ishaan Gulrajani and Percy Liang and Tatsunori B. Hashimoto},
  year          = {2022},
  eprint        = {2205.14217},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{li2023halueval,
  title         = {HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models},
  author        = {Junyi Li and Xiaoxue Cheng and Wayne Xin Zhao and Jian-Yun Nie and Ji-Rong Wen},
  year          = {2023},
  eprint        = {2305.11747},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{li2023prd,
  title         = {PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations},
  author        = {Ruosen Li and Teerth Patel and Xinya Du},
  year          = {2023},
  eprint        = {2307.02762},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{lightman2023lets,
  title         = {Let's Verify Step by Step},
  author        = {Hunter Lightman and Vineet Kosaraju and Yura Burda and Harri Edwards and Bowen Baker and Teddy Lee and Jan Leike and John Schulman and Ilya Sutskever and Karl Cobbe},
  year          = {2023},
  eprint        = {2305.20050},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@inproceedings{liu-liu-2021-simcls,
  title     = {{S}im{CLS}: A Simple Framework for Contrastive Learning of Abstractive Summarization},
  author    = {Liu, Yixin  and
               Liu, Pengfei},
  editor    = {Zong, Chengqing  and
               Xia, Fei  and
               Li, Wenjie  and
               Navigli, Roberto},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)},
  month     = aug,
  year      = {2021},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.acl-short.135},
  doi       = {10.18653/v1/2021.acl-short.135},
  pages     = {1065--1072},
  abstract  = {In this paper, we present a conceptually simple while empirically powerful framework for abstractive summarization, SimCLS, which can bridge the gap between the learning objective and evaluation metrics resulting from the currently dominated sequence-to-sequence learning framework by formulating text generation as a reference-free evaluation problem (i.e., quality estimation) assisted by contrastive learning. Experimental results show that, with minor modification over existing top-scoring systems, SimCLS can improve the performance of existing top-performing models by a large margin. Particularly, 2.51 absolute improvement against BART and 2.50 over PEGASUS w.r.t ROUGE-1 on the CNN/DailyMail dataset, driving the state-of-the-art performance to a new level. We have open-sourced our codes and results: \url{https://github.com/yixinL7/SimCLS}. Results of our proposed models have been deployed into ExplainaBoard platform, which allows researchers to understand our systems in a more fine-grained way.}
}
@article{liu2018generating,
  title   = {Generating wikipedia by summarizing long sequences},
  author  = {Liu, Peter J and Saleh, Mohammad and Pot, Etienne and Goodrich, Ben and Sepassi, Ryan and Kaiser, Lukasz and Shazeer, Noam},
  journal = {arXiv preprint arXiv:1801.10198},
  year    = {2018}
}
@misc{liu2023chain,
  title         = {Chain of Hindsight Aligns Language Models with Feedback},
  author        = {Hao Liu and Carmelo Sferrazza and Pieter Abbeel},
  year          = {2023},
  eprint        = {2302.02676},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@article{liu2023zero,
  title   = {From zero to hero: Examining the power of symbolic tasks in instruction tuning},
  author  = {Liu, Qian and Zhou, Fan and Jiang, Zhengbao and Dou, Longxu and Lin, Min},
  journal = {arXiv preprint arXiv:2304.07995},
  year    = {2023}
}
@misc{lu2022quark,
  title         = {Quark: Controllable Text Generation with Reinforced Unlearning},
  author        = {Ximing Lu and Sean Welleck and Jack Hessel and Liwei Jiang and Lianhui Qin and Peter West and Prithviraj Ammanabrolu and Yejin Choi},
  year          = {2022},
  eprint        = {2205.13636},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{luo2023wizardcoder,
  title         = {WizardCoder: Empowering Code Large Language Models with Evol-Instruct},
  author        = {Ziyang Luo and Can Xu and Pu Zhao and Qingfeng Sun and Xiubo Geng and Wenxiang Hu and Chongyang Tao and Jing Ma and Qingwei Lin and Daxin Jiang},
  year          = {2023},
  eprint        = {2306.08568},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{lyu2023faithful,
  title         = {Faithful Chain-of-Thought Reasoning},
  author        = {Qing Lyu and Shreya Havaldar and Adam Stein and Li Zhang and Delip Rao and Eric Wong and Marianna Apidianaki and Chris Callison-Burch},
  year          = {2023},
  eprint        = {2301.13379},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@inproceedings{madaan-etal-2022-memory,
  title     = {Memory-assisted prompt editing to improve {GPT}-3 after deployment},
  author    = {Madaan, Aman  and
               Tandon, Niket  and
               Clark, Peter  and
               Yang, Yiming},
  editor    = {Goldberg, Yoav  and
               Kozareva, Zornitsa  and
               Zhang, Yue},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  month     = dec,
  year      = {2022},
  address   = {Abu Dhabi, United Arab Emirates},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2022.emnlp-main.183},
  doi       = {10.18653/v1/2022.emnlp-main.183},
  pages     = {2833--2861},
  abstract  = {Large LMs such as GPT-3 are powerful, but can commit mistakes that are obvious to humans. For example, GPT-3 would mistakenly interpret {``}What word is similar to good?{''} to mean a homophone, while the user intended a synonym. Our goal is to effectively correct such errors via user interactions with the system but without retraining, which will be prohibitively costly. We pair GPT-3 with a growing memory of recorded cases where the model misunderstood the user{'}s intents, along with user feedback for clarification. Such a memory allows our system to produce enhanced prompts for any new query based on the user feedback for error correction on similar cases in the past. On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed GPT-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT-3. Our approach is a step towards the low-cost utility enhancement for very large pre-trained LMs.}
}
@misc{madaan2022language,
  title         = {Language Models of Code are Few-Shot Commonsense Learners},
  author        = {Aman Madaan and Shuyan Zhou and Uri Alon and Yiming Yang and Graham Neubig},
  year          = {2022},
  eprint        = {2210.07128},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{madaan2023selfrefine,
  title         = {Self-Refine: Iterative Refinement with Self-Feedback},
  author        = {Aman Madaan and Niket Tandon and Prakhar Gupta and Skyler Hallinan and Luyu Gao and Sarah Wiegreffe and Uri Alon and Nouha Dziri and Shrimai Prabhumoye and Yiming Yang and Shashank Gupta and Bodhisattwa Prasad Majumder and Katherine Hermann and Sean Welleck and Amir Yazdanbakhsh and Peter Clark},
  year          = {2023},
  eprint        = {2303.17651},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{mehrabi2023flirt,
  title         = {FLIRT: Feedback Loop In-context Red Teaming},
  author        = {Ninareh Mehrabi and Palash Goyal and Christophe Dupuy and Qian Hu and Shalini Ghosh and Richard Zemel and Kai-Wei Chang and Aram Galstyan and Rahul Gupta},
  year          = {2023},
  eprint        = {2308.04265},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI}
}
@misc{mialon2023augmented,
  title         = {Augmented Language Models: a Survey},
  author        = {Grégoire Mialon and Roberto Dessì and Maria Lomeli and Christoforos Nalmpantis and Ram Pasunuru and Roberta Raileanu and Baptiste Rozière and Timo Schick and Jane Dwivedi-Yu and Asli Celikyilmaz and Edouard Grave and Yann LeCun and Thomas Scialom},
  year          = {2023},
  eprint        = {2302.07842},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@article{mielke2021between,
  title   = {Between words and characters: a brief history of open-vocabulary modeling and tokenization in nlp},
  author  = {Mielke, Sabrina J and Alyafeai, Zaid and Salesky, Elizabeth and Raffel, Colin and Dey, Manan and Gall{\'e}, Matthias and Raja, Arun and Si, Chenglei and Lee, Wilson Y and Sagot, Beno{\^\i}t and others},
  journal = {arXiv preprint arXiv:2112.10508},
  year    = {2021}
}
@inproceedings{nair2010rectified,
  title     = {Rectified linear units improve restricted boltzmann machines},
  author    = {Nair, Vinod and Hinton, Geoffrey E},
  booktitle = {Proceedings of the 27th international conference on machine learning (ICML-10)},
  pages     = {807--814},
  year      = {2010}
}
@misc{ni2023lever,
  title         = {LEVER: Learning to Verify Language-to-Code Generation with Execution},
  author        = {Ansong Ni and Srini Iyer and Dragomir Radev and Ves Stoyanov and Wen-tau Yih and Sida I. Wang and Xi Victoria Lin},
  year          = {2023},
  eprint        = {2302.08468},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@misc{olausson2023selfrepair,
  title         = {Is Self-Repair a Silver Bullet for Code Generation?},
  author        = {Theo X. Olausson and Jeevana Priya Inala and Chenglong Wang and Jianfeng Gao and Armando Solar-Lezama},
  year          = {2023},
  eprint        = {2306.09896},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{openai2023gpt4,
  title         = {GPT-4 Technical Report},
  author        = {OpenAI and : and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mo Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and Michael and Pokorny and Michelle Pokrass and Vitchyr Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},
  year          = {2023},
  eprint        = {2303.08774},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{ouyang2022training,
  title         = {Training language models to follow instructions with human feedback},
  author        = {Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
  year          = {2022},
  eprint        = {2203.02155},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{pan2023logiclm,
  title         = {Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning},
  author        = {Liangming Pan and Alon Albalak and Xinyi Wang and William Yang Wang},
  year          = {2023},
  eprint        = {2305.12295},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{paul2023refiner,
  title         = {REFINER: Reasoning Feedback on Intermediate Representations},
  author        = {Debjit Paul and Mete Ismayilzada and Maxime Peyrard and Beatriz Borges and Antoine Bosselut and Robert West and Boi Faltings},
  year          = {2023},
  eprint        = {2304.01904},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{peng2023check,
  title         = {Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback},
  author        = {Baolin Peng and Michel Galley and Pengcheng He and Hao Cheng and Yujia Xie and Yu Hu and Qiuyuan Huang and Lars Liden and Zhou Yu and Weizhu Chen and Jianfeng Gao},
  year          = {2023},
  eprint        = {2302.12813},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{peng2023impact,
  title         = {The Impact of AI on Developer Productivity: Evidence from GitHub Copilot},
  author        = {Sida Peng and Eirini Kalliamvakou and Peter Cihon and Mert Demirer},
  year          = {2023},
  eprint        = {2302.06590},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}
@inproceedings{pmlr-v202-lai23b,
  title     = {{DS}-1000: A Natural and Reliable Benchmark for Data Science Code Generation},
  author    = {Lai, Yuhang and Li, Chengxi and Wang, Yiming and Zhang, Tianyi and Zhong, Ruiqi and Zettlemoyer, Luke and Yih, Wen-Tau and Fried, Daniel and Wang, Sida and Yu, Tao},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning},
  pages     = {18319--18345},
  year      = {2023},
  editor    = {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume    = {202},
  series    = {Proceedings of Machine Learning Research},
  month     = {23--29 Jul},
  publisher = {PMLR},
  pdf       = {https://proceedings.mlr.press/v202/lai23b/lai23b.pdf},
  url       = {https://proceedings.mlr.press/v202/lai23b.html},
  abstract  = {We introduce DS-1000, a code generation benchmark with a thousand data science problems spanning seven Python libraries, such as Numpy and Pandas. Compared to prior works, DS-1000 incorporates three core features. First, our problems reflect diverse, realistic, and practical use cases since we collected them from StackOverflow. Second, our automatic evaluation is highly specific (reliable) – across all Codex-002-predicted solutions that our evaluation accepts, only 1.8% of them are incorrect; we achieve this with multi-criteria metrics, checking both functional correctness by running test cases and surface-form constraints by restricting API usages or keywords. Finally, we proactively defend against memorization by slightly modifying our problems to be different from the original StackOverflow source; consequently, models cannot answer them correctly by memorizing the solutions from pre-training. The current best public system (Codex-002) achieves 43.3% accuracy, leaving ample room for improvement. We release our benchmark at https://ds1000-code-gen.github.io.}
}
@article{press2021train,
  title   = {Train short, test long: Attention with linear biases enables input length extrapolation},
  author  = {Press, Ofir and Smith, Noah A and Lewis, Mike},
  journal = {arXiv preprint arXiv:2108.12409},
  year    = {2021}
}
@article{radford2019language,
  title   = {Language models are unsupervised multitask learners},
  author  = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal = {OpenAI blog},
  volume  = {1},
  number  = {8},
  pages   = {9},
  year    = {2019}
}
@article{raffel2020exploring,
  title     = {Exploring the limits of transfer learning with a unified text-to-text transformer},
  author    = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal   = {The Journal of Machine Learning Research},
  volume    = {21},
  number    = {1},
  pages     = {5485--5551},
  year      = {2020},
  publisher = {JMLRORG}
}
@misc{ribeiro2023street,
  title         = {STREET: A Multi-Task Structured Reasoning and Explanation Benchmark},
  author        = {Danilo Ribeiro and Shen Wang and Xiaofei Ma and Henry Zhu and Rui Dong and Deguang Kong and Juliette Burger and Anjelica Ramos and William Wang and Zhiheng Huang and George Karypis and Bing Xiang and Dan Roth},
  year          = {2023},
  eprint        = {2302.06729},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{saravia2022prompt,
  title  = {Prompt Engineering Guide},
  author = {Saravia, Elvis},
  year   = {2022}
}
@misc{scheurer2023training,
  title         = {Training Language Models with Language Feedback at Scale},
  author        = {Jérémy Scheurer and Jon Ander Campos and Tomasz Korbak and Jun Shern Chan and Angelica Chen and Kyunghyun Cho and Ethan Perez},
  year          = {2023},
  eprint        = {2303.16755},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{schick2022peer,
  title         = {PEER: A Collaborative Language Model},
  author        = {Timo Schick and Jane Dwivedi-Yu and Zhengbao Jiang and Fabio Petroni and Patrick Lewis and Gautier Izacard and Qingfei You and Christoforos Nalmpantis and Edouard Grave and Sebastian Riedel},
  year          = {2022},
  eprint        = {2208.11663},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{schick2023toolformer,
  title         = {Toolformer: Language Models Can Teach Themselves to Use Tools},
  author        = {Timo Schick and Jane Dwivedi-Yu and Roberto Dessì and Roberta Raileanu and Maria Lomeli and Luke Zettlemoyer and Nicola Cancedda and Thomas Scialom},
  year          = {2023},
  eprint        = {2302.04761},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{schramowski2022large,
  title         = {Large Pre-trained Language Models Contain Human-like Biases of What is Right and Wrong to Do},
  author        = {Patrick Schramowski and Cigdem Turan and Nico Andersen and Constantin A. Rothkopf and Kristian Kersting},
  year          = {2022},
  eprint        = {2103.11790},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{schulman2017proximal,
  title         = {Proximal Policy Optimization Algorithms},
  author        = {John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
  year          = {2017},
  eprint        = {1707.06347},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@inproceedings{schuster2012japanese,
  title        = {Japanese and korean voice search},
  author       = {Schuster, Mike and Nakajima, Kaisuke},
  booktitle    = {2012 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages        = {5149--5152},
  year         = {2012},
  organization = {IEEE}
}
@misc{selfee2023,
  author       = {Ye, Seonghyeon and Jo, Yongrae and Kim, Doyoung and Kim, Sungdong and Hwang, Hyeonbin and Seo, Minjoon},
  title        = {SelFee: Iterative Self-Revising LLM Empowered by Self-Feedback Generation},
  url          = {https://kaistai.github.io/SelFee/},
  month        = {May},
  year         = {2023},
  howpublished = {Blog post}
}
@inproceedings{sellam-etal-2020-bleurt,
  title     = {{BLEURT}: Learning Robust Metrics for Text Generation},
  author    = {Sellam, Thibault  and
               Das, Dipanjan  and
               Parikh, Ankur},
  editor    = {Jurafsky, Dan  and
               Chai, Joyce  and
               Schluter, Natalie  and
               Tetreault, Joel},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  month     = jul,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.acl-main.704},
  doi       = {10.18653/v1/2020.acl-main.704},
  pages     = {7881--7892},
  abstract  = {Text generation has made significant advances in the last few years. Yet, evaluation metrics have lagged behind, as the most popular choices (e.g., BLEU and ROUGE) may correlate poorly with human judgment. We propose BLEURT, a learned evaluation metric for English based on BERT. BLEURT can model human judgment with a few thousand possibly biased training examples. A key aspect of our approach is a novel pre-training scheme that uses millions of synthetic examples to help the model generalize. BLEURT provides state-of-the-art results on the last three years of the WMT Metrics shared task and the WebNLG data set. In contrast to a vanilla BERT-based approach, it yields superior results even when the training data is scarce and out-of-distribution.}
}
@article{sennrich2015neural,
  title   = {Neural machine translation of rare words with subword units},
  author  = {Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  journal = {arXiv preprint arXiv:1508.07909},
  year    = {2015}
}
@article{Shahaf_Horvitz_2010,
  title        = {Generalized Task Markets for Human and Machine Computation},
  volume       = {24},
  url          = {https://ojs.aaai.org/index.php/AAAI/article/view/7652},
  doi          = {10.1609/aaai.v24i1.7652},
  abstractnote = { &lt;p&gt; We discuss challenges and opportunities for developing generalized task markets where human and machine intelligence are enlisted to solve problems, based on a consideration of the competencies, availabilities, and pricing of different problem-solving resources. The approach couples human computation with machine learning and planning, and is aimed at optimizing the flow of subtasks to people and to computational problem solvers. We illustrate key ideas in the context of Lingua Mechanica, a project focused on harnessing human and machine translation skills to perform translation among languages. We present infrastructure and methods for enlisting and guiding human and machine computation for language translation, including details about the hardness of generating plans for assigning tasks to solvers. Finally, we discuss studies performed with machine and human solvers, focusing on components of a Lingua Mechanica prototype. &lt;/p&gt; },
  number       = {1},
  journal      = {Proceedings of the AAAI Conference on Artificial Intelligence},
  author       = {Shahaf, Dafna and Horvitz, Eric},
  year         = {2010},
  month        = {Jul.},
  pages        = {986-993}
}
@inproceedings{shaikh-etal-2023-second,
  title     = {On Second Thought, Let{'}s Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning},
  author    = {Shaikh, Omar  and
               Zhang, Hongxin  and
               Held, William  and
               Bernstein, Michael  and
               Yang, Diyi},
  editor    = {Rogers, Anna  and
               Boyd-Graber, Jordan  and
               Okazaki, Naoaki},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = jul,
  year      = {2023},
  address   = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.acl-long.244},
  doi       = {10.18653/v1/2023.acl-long.244},
  pages     = {4454--4470},
  abstract  = {Generating a Chain of Thought (CoT) has been shown to consistently improve large language model (LLM) performance on a wide range of NLP tasks. However, prior work has mainly focused on logical reasoning tasks (e.g. arithmetic, commonsense QA); it remains unclear whether improvements hold for more diverse types of reasoning, especially in socially situated contexts. Concretely, we perform a controlled evaluation of zero-shot CoT across two socially sensitive domains: harmful questions and stereotype benchmarks. We find that zero-shot CoT reasoning in sensitive domains significantly increases a model{'}s likelihood to produce harmful or undesirable output, with trends holding across different prompt formats and model variants. Furthermore, we show that harmful CoTs increase with model size, but decrease with improved instruction following. Our work suggests that zero-shot CoT should be used with caution on socially important tasks, especially when marginalized groups or sensitive topics are involved.}
}
@article{shazeer2020glu,
  title   = {Glu variants improve transformer},
  author  = {Shazeer, Noam},
  journal = {arXiv preprint arXiv:2002.05202},
  year    = {2020}
}
@inproceedings{shen-etal-2016-minimum,
  title     = {Minimum Risk Training for Neural Machine Translation},
  author    = {Shen, Shiqi  and
               Cheng, Yong  and
               He, Zhongjun  and
               He, Wei  and
               Wu, Hua  and
               Sun, Maosong  and
               Liu, Yang},
  editor    = {Erk, Katrin  and
               Smith, Noah A.},
  booktitle = {Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = aug,
  year      = {2016},
  address   = {Berlin, Germany},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/P16-1159},
  doi       = {10.18653/v1/P16-1159},
  pages     = {1683--1692}
}
@misc{shinn2023reflexion,
  title         = {Reflexion: Language Agents with Verbal Reinforcement Learning},
  author        = {Noah Shinn and Federico Cassano and Edward Berman and Ashwin Gopinath and Karthik Narasimhan and Shunyu Yao},
  year          = {2023},
  eprint        = {2303.11366},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI}
}
@article{shleifer2021normformer,
  title   = {Normformer: Improved transformer pretraining with extra normalization},
  author  = {Shleifer, Sam and Weston, Jason and Ott, Myle},
  journal = {arXiv preprint arXiv:2110.09456},
  year    = {2021}
}
@misc{singla2015learning,
  title         = {Learning to Hire Teams},
  author        = {Adish Singla and Eric Horvitz and Pushmeet Kohli and Andreas Krause},
  year          = {2015},
  eprint        = {1508.02823},
  archiveprefix = {arXiv},
  primaryclass  = {cs.HC}
}
@misc{solaiman2019release,
  title         = {Release Strategies and the Social Impacts of Language Models},
  author        = {Irene Solaiman and Miles Brundage and Jack Clark and Amanda Askell and Ariel Herbert-Voss and Jeff Wu and Alec Radford and Gretchen Krueger and Jong Wook Kim and Sarah Kreps and Miles McCain and Alex Newhouse and Jason Blazakis and Kris McGuffie and Jasmine Wang},
  year          = {2019},
  eprint        = {1908.09203},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@article{srivastava2014dropout,
  title     = {Dropout: a simple way to prevent neural networks from overfitting},
  author    = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal   = {The journal of machine learning research},
  volume    = {15},
  number    = {1},
  pages     = {1929--1958},
  year      = {2014},
  publisher = {JMLR. org}
}
@article{su2024roformer,
  title     = {Roformer: Enhanced transformer with rotary position embedding},
  author    = {Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
  journal   = {Neurocomputing},
  volume    = {568},
  pages     = {127063},
  year      = {2024},
  publisher = {Elsevier}
}
@article{sun2023principle,
  title   = {Principle-driven self-alignment of language models from scratch with minimal human supervision},
  author  = {Sun, Zhiqing and Shen, Yikang and Zhou, Qinhong and Zhang, Hongxin and Chen, Zhenfang and Cox, David and Yang, Yiming and Gan, Chuang},
  journal = {arXiv preprint arXiv:2305.03047},
  year    = {2023}
}
@inproceedings{tafjord-etal-2022-entailer,
  title     = {Entailer: Answering Questions with Faithful and Truthful Chains of Reasoning},
  author    = {Tafjord, Oyvind  and
               Dalvi Mishra, Bhavana  and
               Clark, Peter},
  editor    = {Goldberg, Yoav  and
               Kozareva, Zornitsa  and
               Zhang, Yue},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  month     = dec,
  year      = {2022},
  address   = {Abu Dhabi, United Arab Emirates},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2022.emnlp-main.134},
  doi       = {10.18653/v1/2022.emnlp-main.134},
  pages     = {2078--2093},
  abstract  = {Our goal is a question-answering (QA) system that can show how its answers are implied by its own internal beliefs via a systematic chain of reasoning. Such a capability would allow better understanding of why a model produced the answer it did. Our approach is to recursively combine a trained backward-chainingmodel, capable of generating a set of premises entailing an answer hypothesis, with a verifier that checks that the model itself believes those premises (and the entailment itself) through self-querying. To our knowledge, this is the first system to generate multistep chains that are both faithful (the answer follows from the reasoning) and truthful (the chain reflects the system{'}s own internal beliefs). In evaluation using two different datasets, users judge that a majority (70{\%}+) of generated chains clearly show how an answer follows from a set of facts - substantially better than a high-performance baseline - while preserving answer accuracy. By materializing model beliefs that systematically support an answer, new opportunities arise for understanding the model{'}s system of belief, and diagnosing and correcting its misunderstandings when an answer is wrong.}
}
@article{tay2022unifying,
  title   = {Unifying language learning paradigms},
  author  = {Tay, Yi and Dehghani, Mostafa and Tran, Vinh Q and Garcia, Xavier and Bahri, Dara and Schuster, Tal and Zheng, Huaixiu Steven and Houlsby, Neil and Metzler, Donald},
  journal = {arXiv preprint arXiv:2205.05131},
  year    = {2022}
}
@misc{thoppilan2022lamda,
  title         = {LaMDA: Language Models for Dialog Applications},
  author        = {Romal Thoppilan and Daniel De Freitas and Jamie Hall and Noam Shazeer and Apoorv Kulshreshtha and Heng-Tze Cheng and Alicia Jin and Taylor Bos and Leslie Baker and Yu Du and YaGuang Li and Hongrae Lee and Huaixiu Steven Zheng and Amin Ghafouri and Marcelo Menegali and Yanping Huang and Maxim Krikun and Dmitry Lepikhin and James Qin and Dehao Chen and Yuanzhong Xu and Zhifeng Chen and Adam Roberts and Maarten Bosma and Vincent Zhao and Yanqi Zhou and Chung-Ching Chang and Igor Krivokon and Will Rusch and Marc Pickett and Pranesh Srinivasan and Laichee Man and Kathleen Meier-Hellstern and Meredith Ringel Morris and Tulsee Doshi and Renelito Delos Santos and Toju Duke and Johnny Soraker and Ben Zevenbergen and Vinodkumar Prabhakaran and Mark Diaz and Ben Hutchinson and Kristen Olson and Alejandra Molina and Erin Hoffman-John and Josh Lee and Lora Aroyo and Ravi Rajakumar and Alena Butryna and Matthew Lamm and Viktoriya Kuzmina and Joe Fenton and Aaron Cohen and Rachel Bernstein and Ray Kurzweil and Blaise Aguera-Arcas and Claire Cui and Marian Croak and Ed Chi and Quoc Le},
  year          = {2022},
  eprint        = {2201.08239},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@article{touvron2023llama,
  title   = {Llama 2: Open foundation and fine-tuned chat models},
  author  = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal = {arXiv preprint arXiv:2307.09288},
  year    = {2023}
}
@misc{uesato2022solving,
  title         = {Solving math word problems with process- and outcome-based feedback},
  author        = {Jonathan Uesato and Nate Kushman and Ramana Kumar and Francis Song and Noah Siegel and Lisa Wang and Antonia Creswell and Geoffrey Irving and Irina Higgins},
  year          = {2022},
  eprint        = {2211.14275},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@misc{varshney2023stitch,
  title         = {A Stitch in Time Saves Nine: Detecting and Mitigating Hallucinations of LLMs by Validating Low-Confidence Generation},
  author        = {Neeraj Varshney and Wenlin Yao and Hongming Zhang and Jianshu Chen and Dong Yu},
  year          = {2023},
  eprint        = {2307.03987},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@article{vaswani2017attention,
  title   = {Attention is all you need},
  author  = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal = {Advances in neural information processing systems},
  volume  = {30},
  year    = {2017}
}
@article{wang2022deepnet,
  title   = {Deepnet: Scaling transformers to 1,000 layers},
  author  = {Wang, Hongyu and Ma, Shuming and Dong, Li and Huang, Shaohan and Zhang, Dongdong and Wei, Furu},
  journal = {arXiv preprint arXiv:2203.00555},
  year    = {2022}
}
@inproceedings{wang2022language,
  title        = {What language model architecture and pretraining objective works best for zero-shot generalization?},
  author       = {Wang, Thomas and Roberts, Adam and Hesslow, Daniel and Le Scao, Teven and Chung, Hyung Won and Beltagy, Iz and Launay, Julien and Raffel, Colin},
  booktitle    = {International Conference on Machine Learning},
  pages        = {22964--22984},
  year         = {2022},
  organization = {PMLR}
}
@article{wang2022self,
  title   = {Self-consistency improves chain of thought reasoning in language models},
  author  = {Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal = {arXiv preprint arXiv:2203.11171},
  year    = {2022}
}
@article{wang2022super,
  title   = {Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks},
  author  = {Wang, Yizhong and Mishra, Swaroop and Alipoormolabashi, Pegah and Kordi, Yeganeh and Mirzaei, Amirreza and Arunkumar, Anjana and Ashok, Arjun and Dhanasekaran, Arut Selvan and Naik, Atharva and Stap, David and others},
  journal = {arXiv preprint arXiv:2204.07705},
  year    = {2022}
}
@misc{wang2023aligning,
  title         = {Aligning Large Language Models with Human: A Survey},
  author        = {Yufei Wang and Wanjun Zhong and Liangyou Li and Fei Mi and Xingshan Zeng and Wenyong Huang and Lifeng Shang and Xin Jiang and Qun Liu},
  year          = {2023},
  eprint        = {2307.12966},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{wang2023selfconsistency,
  title         = {Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  author        = {Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc Le and Ed Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou},
  year          = {2023},
  eprint        = {2203.11171},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@inproceedings{webster1992tokenization,
  title     = {Tokenization as the initial phase in NLP},
  author    = {Webster, Jonathan J and Kit, Chunyu},
  booktitle = {COLING 1992 volume 4: The 14th international conference on computational linguistics},
  year      = {1992}
}
@article{wei2022chain,
  title   = {Chain-of-thought prompting elicits reasoning in large language models},
  author  = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {35},
  pages   = {24824--24837},
  year    = {2022}
}
@misc{wei2023chainofthought,
  title         = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author        = {Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
  year          = {2023},
  eprint        = {2201.11903},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{weidinger2021ethical,
  title         = {Ethical and social risks of harm from Language Models},
  author        = {Laura Weidinger and John Mellor and Maribeth Rauh and Conor Griffin and Jonathan Uesato and Po-Sen Huang and Myra Cheng and Mia Glaese and Borja Balle and Atoosa Kasirzadeh and Zac Kenton and Sasha Brown and Will Hawkins and Tom Stepleton and Courtney Biles and Abeba Birhane and Julia Haas and Laura Rimell and Lisa Anne Hendricks and William Isaac and Sean Legassick and Geoffrey Irving and Iason Gabriel},
  year          = {2021},
  eprint        = {2112.04359},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{welleck2022generating,
  title         = {Generating Sequences by Learning to Self-Correct},
  author        = {Sean Welleck and Ximing Lu and Peter West and Faeze Brahman and Tianxiao Shen and Daniel Khashabi and Yejin Choi},
  year          = {2022},
  eprint        = {2211.00053},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{weng2023large,
  title         = {Large Language Models are Better Reasoners with Self-Verification},
  author        = {Yixuan Weng and Minjun Zhu and Fei Xia and Bin Li and Shizhu He and Shengping Liu and Bin Sun and Kang Liu and Jun Zhao},
  year          = {2023},
  eprint        = {2212.09561},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI}
}
@misc{wu2021textgail,
  title         = {TextGAIL: Generative Adversarial Imitation Learning for Text Generation},
  author        = {Qingyang Wu and Lei Li and Zhou Yu},
  year          = {2021},
  eprint        = {2004.13796},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{xie2023selfevaluation,
  title         = {Self-Evaluation Guided Beam Search for Reasoning},
  author        = {Yuxi Xie and Kenji Kawaguchi and Yiran Zhao and Xu Zhao and Min-Yen Kan and Junxian He and Qizhe Xie},
  year          = {2023},
  eprint        = {2305.00633},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@inproceedings{xu-etal-2022-errors,
  title     = {Not All Errors are Equal: Learning Text Generation Metrics using Stratified Error Synthesis},
  author    = {Xu, Wenda  and
               Tuan, Yi-Lin  and
               Lu, Yujie  and
               Saxon, Michael  and
               Li, Lei  and
               Wang, William Yang},
  editor    = {Goldberg, Yoav  and
               Kozareva, Zornitsa  and
               Zhang, Yue},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2022},
  month     = dec,
  year      = {2022},
  address   = {Abu Dhabi, United Arab Emirates},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2022.findings-emnlp.489},
  doi       = {10.18653/v1/2022.findings-emnlp.489},
  pages     = {6559--6574},
  abstract  = {Is it possible to build a general and automatic natural language generation (NLG) evaluation metric? Existing learned metrics either perform unsatisfactorily or are restricted to tasks where large human rating data is already available. We introduce SESCORE, a model-based metric that is highly correlated with human judgements without requiring human annotation, by utilizing a novel, iterative error synthesis and severity scoring pipeline. This pipeline applies a series of plausible errors to raw text and assigns severity labels by simulating human judgements with entailment. We evaluate SESCORE against existing metrics by comparing how their scores correlate with human ratings. SESCORE outperforms all prior unsupervised metrics on multiple diverse NLG tasks including machine translation, image captioning, and WebNLG text generation. For WMT 20/21En-De and Zh-En, SESCORE improve the average Kendall correlation with human judgement from 0.154 to 0.195. SESCORE even achieves comparable performance to the best supervised metric COMET, despite receiving no human annotated training data.}
}
@inproceedings{xu-etal-2023-sescore2,
  title     = {{SESCORE}2: Learning Text Generation Evaluation via Synthesizing Realistic Mistakes},
  author    = {Xu, Wenda  and
               Qian, Xian  and
               Wang, Mingxuan  and
               Li, Lei  and
               Wang, William Yang},
  editor    = {Rogers, Anna  and
               Boyd-Graber, Jordan  and
               Okazaki, Naoaki},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = jul,
  year      = {2023},
  address   = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.acl-long.283},
  doi       = {10.18653/v1/2023.acl-long.283},
  pages     = {5166--5183},
  abstract  = {Is it possible to train a general metric for evaluating text generation quality without human-annotated ratings? Existing learned metrics either perform unsatisfactory across text generation tasks or require human ratings for training on specific tasks. In this paper, we propose SEScore2, a self-supervised approach for training a model-based metric for text generation evaluation. The key concept is to synthesize realistic model mistakes by perturbing sentences retrieved from a corpus. We evaluate SEScore2 and previous methods on four text generation tasks across three languages. SEScore2 outperforms all prior unsupervised metrics on four text generation evaluation benchmarks, with an average Kendall improvement of 0.158. Surprisingly, SEScore2 even outperforms the supervised BLEURT and COMET on multiple text generation tasks.}
}
@article{xue2020mt5,
  title   = {mT5: A massively multilingual pre-trained text-to-text transformer},
  author  = {Xue, Linting and Constant, Noah and Roberts, Adam and Kale, Mihir and Al-Rfou, Rami and Siddhant, Aditya and Barua, Aditya and Raffel, Colin},
  journal = {arXiv preprint arXiv:2010.11934},
  year    = {2020}
}
@inproceedings{yan-etal-2023-bleurt,
  title     = {{BLEURT} Has Universal Translations: An Analysis of Automatic Metrics by Minimum Risk Training},
  author    = {Yan, Yiming  and
               Wang, Tao  and
               Zhao, Chengqi  and
               Huang, Shujian  and
               Chen, Jiajun  and
               Wang, Mingxuan},
  editor    = {Rogers, Anna  and
               Boyd-Graber, Jordan  and
               Okazaki, Naoaki},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = jul,
  year      = {2023},
  address   = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.acl-long.297},
  doi       = {10.18653/v1/2023.acl-long.297},
  pages     = {5428--5443},
  abstract  = {Automatic metrics play a crucial role in machine translation. Despite the widespread use of n-gram-based metrics, there has been a recent surge in the development of pre-trained model-based metrics that focus on measuring sentence semantics. However, these neural metrics, while achieving higher correlations with human evaluations, are often considered to be black boxes with potential biases that are difficult to detect. In this study, we systematically analyze and compare various mainstream and cutting-edge automatic metrics from the perspective of their guidance for training machine translation systems. Through Minimum Risk Training (MRT), we find that certain metrics exhibit robustness defects, such as the presence of universal adversarial translations in BLEURT and BARTScore. In-depth analysis suggests two main causes of these robustness deficits: distribution biases in the training datasets, and the tendency of the metric paradigm. By incorporating token-level constraints, we enhance the robustness of evaluation metrics, which in turn leads to an improvement in the performance of machine translation systems. Codes are available at \url{https://github.com/powerpuffpomelo/fairseq_mrt}.}
}
@inproceedings{yan-etal-2023-learning,
  title     = {Learning to Simulate Natural Language Feedback for Interactive Semantic Parsing},
  author    = {Yan, Hao  and
               Srivastava, Saurabh  and
               Tai, Yintao  and
               Wang, Sida I.  and
               Yih, Wen-tau  and
               Yao, Ziyu},
  editor    = {Rogers, Anna  and
               Boyd-Graber, Jordan  and
               Okazaki, Naoaki},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = jul,
  year      = {2023},
  address   = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.acl-long.177},
  doi       = {10.18653/v1/2023.acl-long.177},
  pages     = {3149--3170},
  abstract  = {Interactive semantic parsing based on natural language (NL) feedback, where users provide feedback to correct the parser mistakes, has emerged as a more practical scenario than the traditional one-shot semantic parsing. However, prior work has heavily relied on human-annotated feedback data to train the interactive semantic parser, which is prohibitively expensive and not scalable. In this work, we propose a new task of simulating NL feedback for interactive semantic parsing. We accompany the task with a novel feedback evaluator. The evaluator is specifically designed to assess the quality of the simulated feedback, based on which we decide the best feedback simulator from our proposed variants. On a text-to-SQL dataset, we show that our feedback simulator can generate high-quality NL feedback to boost the error correction ability of a specific parser. In low-data settings, our feedback simulator can help achieve comparable error correction performance as trained using the costly, full set of human annotations.}
}
@inproceedings{yang-etal-2022-generating,
  title     = {Generating Natural Language Proofs with Verifier-Guided Search},
  author    = {Yang, Kaiyu  and
               Deng, Jia  and
               Chen, Danqi},
  editor    = {Goldberg, Yoav  and
               Kozareva, Zornitsa  and
               Zhang, Yue},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  month     = dec,
  year      = {2022},
  address   = {Abu Dhabi, United Arab Emirates},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2022.emnlp-main.7},
  doi       = {10.18653/v1/2022.emnlp-main.7},
  pages     = {89--105},
  abstract  = {Reasoning over natural language is a challenging problem in NLP. In this work, we focus on proof generation: Given a hypothesis and a set of supporting facts, the model generates a proof tree indicating how to derive the hypothesis from supporting facts. Compared to generating the entire proof in one shot, stepwise generation can better exploit the compositionality and generalize to longer proofs but has achieved limited success on real-world data. Existing stepwise methods struggle to generate proof steps that are both logically valid and relevant to the hypothesis. Instead, they tend to hallucinate invalid steps given the hypothesis. In this paper, we present a novel stepwise method, NLProofS (Natural Language Proof Search), which learns to generate relevant steps conditioning on the hypothesis. At the core of our approach, we train an independent verifier to check the validity of the proof steps to prevent hallucination. Instead of generating steps greedily, we search for proofs maximizing a global proof score judged by the verifier. NLProofS achieves state-of-the-art performance on EntailmentBank and RuleTaker. Specifically, it improves the correctness of predicted proofs from 27.7{\%} to 33.3{\%} in the distractor setting of EntailmentBank, demonstrating the effectiveness of NLProofS in generating challenging human-authored proofs.}
}
@inproceedings{yang-etal-2022-re3,
  title     = {Re3: Generating Longer Stories With Recursive Reprompting and Revision},
  author    = {Yang, Kevin  and
               Tian, Yuandong  and
               Peng, Nanyun  and
               Klein, Dan},
  editor    = {Goldberg, Yoav  and
               Kozareva, Zornitsa  and
               Zhang, Yue},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  month     = dec,
  year      = {2022},
  address   = {Abu Dhabi, United Arab Emirates},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2022.emnlp-main.296},
  doi       = {10.18653/v1/2022.emnlp-main.296},
  pages     = {4393--4479},
  abstract  = {We consider the problem of automatically generating longer stories of over two thousand words. Compared to prior work on shorter stories, long-range plot coherence and relevance are more central challenges here. We propose the Recursive Reprompting and Revision framework (Re3) to address these challenges by (a) prompting a general-purpose language model to construct a structured overarching plan, and (b) generating story passages by repeatedly injecting contextual information from both the plan and current story state into a language model prompt. We then revise by (c) reranking different continuations for plot coherence and premise relevance, and finally (d) editing the best continuation for factual consistency. Compared to similar-length stories generated directly from the same base model, human evaluators judged substantially more of Re3{'}s stories as having a coherent overarching plot (by 14{\%} absolute increase), and relevant to the given initial premise (by 20{\%}).}
}
@inproceedings{yang-klein-2021-fudge,
  title     = {{FUDGE}: Controlled Text Generation With Future Discriminators},
  author    = {Yang, Kevin  and
               Klein, Dan},
  editor    = {Toutanova, Kristina  and
               Rumshisky, Anna  and
               Zettlemoyer, Luke  and
               Hakkani-Tur, Dilek  and
               Beltagy, Iz  and
               Bethard, Steven  and
               Cotterell, Ryan  and
               Chakraborty, Tanmoy  and
               Zhou, Yichao},
  booktitle = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  month     = jun,
  year      = {2021},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.naacl-main.276},
  doi       = {10.18653/v1/2021.naacl-main.276},
  pages     = {3511--3535},
  abstract  = {We propose Future Discriminators for Generation (FUDGE), a flexible and modular method for controlled text generation. Given a pre-existing model G for generating text from a distribution of interest, FUDGE enables conditioning on a desired attribute a (for example, formality) while requiring access only to G{'}s output logits. FUDGE learns an attribute predictor operating on a partial sequence, and uses this predictor{'}s outputs to adjust G{'}s original probabilities. We show that FUDGE models terms corresponding to a Bayesian decomposition of the conditional distribution of G given attribute a. Moreover, FUDGE can easily compose predictors for multiple desired attributes. We evaluate FUDGE on three tasks {---} couplet completion in poetry, topic control in language generation, and formality change in machine translation {---} and observe gains in all three tasks.}
}
@misc{yao2023tree,
  title         = {Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
  author        = {Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L. Griffiths and Yuan Cao and Karthik Narasimhan},
  year          = {2023},
  eprint        = {2305.10601},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{yu2023improving,
  title         = {Improving Language Models via Plug-and-Play Retrieval Feedback},
  author        = {Wenhao Yu and Zhihan Zhang and Zhenwen Liang and Meng Jiang and Ashish Sabharwal},
  year          = {2023},
  eprint        = {2305.14002},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{zelikman2022star,
  title         = {STaR: Bootstrapping Reasoning With Reasoning},
  author        = {Eric Zelikman and Yuhuai Wu and Jesse Mu and Noah D. Goodman},
  year          = {2022},
  eprint        = {2203.14465},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@article{zhang2019root,
  title   = {Root mean square layer normalization},
  author  = {Zhang, Biao and Sennrich, Rico},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {32},
  year    = {2019}
}
@misc{zhang2020bertscore,
  title         = {BERTScore: Evaluating Text Generation with BERT},
  author        = {Tianyi Zhang and Varsha Kishore and Felix Wu and Kilian Q. Weinberger and Yoav Artzi},
  year          = {2020},
  eprint        = {1904.09675},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{zhang2023algo,
  title         = {ALGO: Synthesizing Algorithmic Programs with LLM-Generated Oracle Verifiers},
  author        = {Kexun Zhang and Danqing Wang and Jingtao Xia and William Yang Wang and Lei Li},
  year          = {2023},
  eprint        = {2305.14591},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{zhang2023language,
  title         = {How Language Model Hallucinations Can Snowball},
  author        = {Muru Zhang and Ofir Press and William Merrill and Alisa Liu and Noah A. Smith},
  year          = {2023},
  eprint        = {2305.13534},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@misc{zhang2023selfedit,
  title         = {Self-Edit: Fault-Aware Code Editor for Code Generation},
  author        = {Kechi Zhang and Zhuo Li and Jia Li and Ge Li and Zhi Jin},
  year          = {2023},
  eprint        = {2305.04087},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}
@article{zhao2023survey,
  title   = {A survey of large language models},
  author  = {Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal = {arXiv preprint arXiv:2303.18223},
  year    = {2023}
}
@inproceedings{zhu-etal-2023-solving,
  title     = {Solving Math Word Problems via Cooperative Reasoning induced Language Models},
  author    = {Zhu, Xinyu  and
               Wang, Junjie  and
               Zhang, Lin  and
               Zhang, Yuxiang  and
               Huang, Yongfeng  and
               Gan, Ruyi  and
               Zhang, Jiaxing  and
               Yang, Yujiu},
  editor    = {Rogers, Anna  and
               Boyd-Graber, Jordan  and
               Okazaki, Naoaki},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = jul,
  year      = {2023},
  address   = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.acl-long.245},
  doi       = {10.18653/v1/2023.acl-long.245},
  pages     = {4471--4485},
  abstract  = {Large-scale pre-trained language models (PLMs) bring new opportunities to challenging problems, especially those that need high-level intelligence, such as the math word problem (MWPs). However, directly applying existing PLMs to MWPs can fail as the generation process lacks sufficient supervision and thus lacks fast adaptivity as humans. We notice that human reasoning has a dual reasoning framework that consists of an immediate reaction system (system 1) and a delicate reasoning system (system 2), where the entire reasoning is determined by their interaction. This inspires us to develop a cooperative reasoning-induced PLM for solving MWPs, called Cooperative Reasoning (CoRe), resulting in a human-like reasoning architecture with system 1 as the generator and system 2 as the verifier. In our approach, the generator is responsible for generating reasoning paths, and the verifiers are used to supervise the evaluation in order to obtain reliable feedback for the generator. We evaluate our CoRe framework on several mathematical reasoning datasets and achieve decent improvement over state-of-the-art methods, up to 9.6{\%} increase over best baselines.}
}
@article{ziegler2019fine,
  title   = {Fine-tuning language models from human preferences},
  author  = {Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal = {arXiv preprint arXiv:1909.08593},
  year    = {2019}
}
@misc{jiang2023selfevolve,
  title         = {SelfEvolve: A Code Evolution Framework via Large Language Models},
  author        = {Shuyang Jiang and Yuhao Wang and Yu Wang},
  year          = {2023},
  eprint        = {2306.02907},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@inproceedings{robertson1994some,
  title        = {Some simple effective approximations to the 2-poisson model for probabilistic weighted retrieval},
  author       = {Robertson, Stephen E and Walker, Steve},
  booktitle    = {SIGIR’94: Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, organised by Dublin City University},
  pages        = {232--241},
  year         = {1994},
  organization = {Springer}
}
@article{reimers2019sentence,
  title   = {Sentence-bert: Sentence embeddings using siamese bert-networks},
  author  = {Reimers, Nils and Gurevych, Iryna},
  journal = {arXiv preprint arXiv:1908.10084},
  year    = {2019}
}
@article{gao2021simcse,
  title   = {Simcse: Simple contrastive learning of sentence embeddings},
  author  = {Gao, Tianyu and Yao, Xingcheng and Chen, Danqi},
  journal = {arXiv preprint arXiv:2104.08821},
  year    = {2021}
}
@inproceedings{borgeaud2022improving,
  title        = {Improving language models by retrieving from trillions of tokens},
  author       = {Borgeaud, Sebastian and Mensch, Arthur and Hoffmann, Jordan and Cai, Trevor and Rutherford, Eliza and Millican, Katie and Van Den Driessche, George Bm and Lespiau, Jean-Baptiste and Damoc, Bogdan and Clark, Aidan and others},
  booktitle    = {International conference on machine learning},
  pages        = {2206--2240},
  year         = {2022},
  organization = {PMLR}
}
@article{li2023context,
  title   = {In-context learning with many demonstration examples},
  author  = {Li, Mukai and Gong, Shansan and Feng, Jiangtao and Xu, Yiheng and Zhang, Jun and Wu, Zhiyong and Kong, Lingpeng},
  journal = {arXiv preprint arXiv:2302.04931},
  year    = {2023}
}
@article{geva2020transformer,
  title   = {Transformer feed-forward layers are key-value memories},
  author  = {Geva, Mor and Schuster, Roei and Berant, Jonathan and Levy, Omer},
  journal = {arXiv preprint arXiv:2012.14913},
  year    = {2020}
}
@article{zhang2022automatic,
  title   = {Automatic chain of thought prompting in large language models},
  author  = {Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Smola, Alex},
  journal = {arXiv preprint arXiv:2210.03493},
  year    = {2022}
}
