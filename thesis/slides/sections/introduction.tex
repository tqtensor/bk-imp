\section{Introduction}

\begin{frame}{Introduction}
    The rise of Large Language Models (LLMs) is transforming software development. However, their current application primarily relies on zero-shot learning, limiting their ability to tackle complex programming tasks.

    \vspace{0.5cm}

    Can we unlock the full potential of LLMs for sophisticated software development by empowering them with reasoning capabilities and domain-specific knowledge?

    \begin{figure}[!htb]
        \centering
        \includegraphics[width=0.5\textwidth]{img/llm_for_coding}
    \end{figure}
\end{frame}

\begin{frame}{Introduction}
    This thesis introduces \textbf{CoT-SelfEvolve}, a novel framework that enhances LLMs through:

    \begin{itemize}
        \item \textbf{Chain-of-Thought prompting} to guide LLM reasoning.
        \item \textbf{Integration of external knowledge} from StackOverflow to provide domain-specific context.
    \end{itemize}

    \begin{figure}[!htb]
        \centering
        \includegraphics[width=0.8\textwidth]{img/cot_selfevolve_architecture}
        \captionsetup{font=small,labelformat=empty}
        \caption{Architecture of the CoT-SelfEvolve model (this study).}
    \end{figure}
\end{frame}
