{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from string import digits\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from keras.layers import Embedding\n",
    "from openai import AzureOpenAI\n",
    "from pyvi import ViTokenizer\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import (Conv1D, Dense, Dropout, Embedding,\n",
    "                                     Flatten, Input, MaxPooling1D, Reshape,\n",
    "                                     concatenate)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7lMy03omg93",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"vlsp_sentiment_train.csv\", sep=\"\\t\")\n",
    "data_train.columns = [\"Class\", \"Data\"]\n",
    "data_test = pd.read_csv(\"vlsp_sentiment_test.csv\", sep=\"\\t\")\n",
    "data_test.columns = [\"Class\", \"Data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 944,
     "status": "ok",
     "timestamp": 1653989301990,
     "user": {
      "displayName": "Đức Nguyễn Quang",
      "userId": "15255943122151670013"
     },
     "user_tz": -420
    },
    "id": "4HR1jAzImg94",
    "outputId": "8e324c8c-0dbb-4a69-aeff-b03e40766c7e"
   },
   "outputs": [],
   "source": [
    "print(data_train.shape)\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvrbwPfZmg95"
   },
   "outputs": [],
   "source": [
    "labels = data_train.iloc[:, 0].values\n",
    "reviews = data_train.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3HlbVeHimg95"
   },
   "outputs": [],
   "source": [
    "encoded_labels = []\n",
    "\n",
    "for label in labels:\n",
    "    if label == -1:\n",
    "        encoded_labels.append([1, 0, 0])\n",
    "    elif label == 0:\n",
    "        encoded_labels.append([0, 1, 0])\n",
    "    else:\n",
    "        encoded_labels.append([0, 0, 1])\n",
    "\n",
    "encoded_labels = np.array(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lm4OCwxXmg96"
   },
   "outputs": [],
   "source": [
    "reviews_processed = []\n",
    "unlabeled_processed = []\n",
    "for review in reviews:\n",
    "    review_cool_one = \"\".join([char for char in review if char not in digits])\n",
    "    reviews_processed.append(review_cool_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nW2OZgkgmg97"
   },
   "outputs": [],
   "source": [
    "# Use PyVi for Vietnamese word tokenizer\n",
    "word_reviews = []\n",
    "all_words = []\n",
    "for review in reviews_processed:\n",
    "    review = ViTokenizer.tokenize(review.lower())\n",
    "    word_reviews.append(review.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pTb0MeDRmg98"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 1536  # OpenAI embedding dimension\n",
    "MAX_VOCAB_SIZE = (\n",
    "    10000  # how many unique words to use (i.e num rows in embedding vector)\n",
    ")\n",
    "MAX_SEQUENCE_LENGTH = 300  # max number of words in a comment to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-BHpPSLTmg9_"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, lower=True, char_level=False)\n",
    "tokenizer.fit_on_texts(word_reviews)\n",
    "sequences_train = tokenizer.texts_to_sequences(word_reviews)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LlV3M2dimg9_"
   },
   "outputs": [],
   "source": [
    "data = pad_sequences(sequences_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "labels = encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1653989306259,
     "user": {
      "displayName": "Đức Nguyễn Quang",
      "userId": "15255943122151670013"
     },
     "user_tz": -420
    },
    "id": "4dl9VZ3Rmg-A",
    "outputId": "0d43e170-e903-4d5b-f3ec-18a8b911d072"
   },
   "outputs": [],
   "source": [
    "print(\"Shape of X train and X validation tensor:\", data.shape)\n",
    "print(\"Shape of label train and validation tensor:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KKSjJdJmg-A"
   },
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    ")\n",
    "\n",
    "vocabulary_size = min(len(word_index) + 1, MAX_VOCAB_SIZE)\n",
    "embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    if i >= MAX_VOCAB_SIZE:\n",
    "        continue\n",
    "    try:\n",
    "        embedding_vector = client.embeddings.create(\n",
    "            input=word, model=\"text-embedding-ada-002\"\n",
    "        ).model_dump()[\"data\"][0][\"embedding\"]\n",
    "        embedding_matrix[i] = np.asarray(embedding_vector)\n",
    "    except KeyError:\n",
    "        embedding_matrix[i] = np.random.normal(0, np.sqrt(0.25), EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(vocabulary_size, EMBEDDING_DIM)\n",
    "embedding_layer.trainable = True\n",
    "embedding_layer.set_weights = [embedding_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 381,
     "status": "ok",
     "timestamp": 1653989417080,
     "user": {
      "displayName": "Đức Nguyễn Quang",
      "userId": "15255943122151670013"
     },
     "user_tz": -420
    },
    "id": "njBANdn5mg-B",
    "outputId": "24647910-9144-4987-83a2-fe64e64a04ac"
   },
   "outputs": [],
   "source": [
    "sequence_length = data.shape[1]\n",
    "filter_sizes = [3, 4, 5]\n",
    "num_filters = 100\n",
    "drop = 0.5\n",
    "\n",
    "inputs = Input(shape=(sequence_length,))\n",
    "embedding = embedding_layer(inputs)\n",
    "\n",
    "conv_0 = Conv1D(\n",
    "    num_filters,\n",
    "    filter_sizes[0],\n",
    "    activation=\"relu\",\n",
    "    kernel_regularizer=regularizers.l2(0.01),\n",
    ")(embedding)\n",
    "conv_1 = Conv1D(\n",
    "    num_filters,\n",
    "    filter_sizes[1],\n",
    "    activation=\"relu\",\n",
    "    kernel_regularizer=regularizers.l2(0.01),\n",
    ")(embedding)\n",
    "conv_2 = Conv1D(\n",
    "    num_filters,\n",
    "    filter_sizes[2],\n",
    "    activation=\"relu\",\n",
    "    kernel_regularizer=regularizers.l2(0.01),\n",
    ")(embedding)\n",
    "\n",
    "maxpool_0 = MaxPooling1D(sequence_length - filter_sizes[0] + 1, strides=1)(\n",
    "    conv_0\n",
    ")\n",
    "maxpool_1 = MaxPooling1D(sequence_length - filter_sizes[1] + 1, strides=1)(\n",
    "    conv_1\n",
    ")\n",
    "maxpool_2 = MaxPooling1D(sequence_length - filter_sizes[2] + 1, strides=1)(\n",
    "    conv_2\n",
    ")\n",
    "\n",
    "merged_tensor = concatenate([maxpool_0, maxpool_1, maxpool_2], axis=1)\n",
    "flatten = Flatten()(merged_tensor)\n",
    "reshape = Reshape((3 * num_filters,))(flatten)\n",
    "dropout = Dropout(drop)(flatten)\n",
    "output = Dense(\n",
    "    units=3, activation=\"softmax\", kernel_regularizer=regularizers.l2(0.01)\n",
    ")(dropout)\n",
    "\n",
    "# This creates a model that includes\n",
    "model = Model(inputs, output)\n",
    "\n",
    "adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", optimizer=adam, metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", min_delta=0.01, patience=4, verbose=1\n",
    ")\n",
    "callbacks_list = [early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10375,
     "status": "ok",
     "timestamp": 1653989547863,
     "user": {
      "displayName": "Đức Nguyễn Quang",
      "userId": "15255943122151670013"
     },
     "user_tz": -420
    },
    "id": "Jn0dBlzjmg-D",
    "outputId": "be7de957-bf78-4fff-bc31-b5e586f705fa"
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    data,\n",
    "    labels,\n",
    "    validation_split=0.2,\n",
    "    epochs=5,\n",
    "    batch_size=256,\n",
    "    callbacks=callbacks_list,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8XoN2UOamg-D"
   },
   "outputs": [],
   "source": [
    "labels_test = data_test.iloc[:, 0].values\n",
    "reviews_test = data_test.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PwiYb3Ohmg-E"
   },
   "outputs": [],
   "source": [
    "encoded_labels_test = []\n",
    "\n",
    "for label_test in labels_test:\n",
    "    if label_test == -1:\n",
    "        encoded_labels_test.append([1, 0, 0])\n",
    "    elif label_test == 0:\n",
    "        encoded_labels_test.append([0, 1, 0])\n",
    "    else:\n",
    "        encoded_labels_test.append([0, 0, 1])\n",
    "\n",
    "encoded_labels_test = np.array(encoded_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E08tBw9img-E"
   },
   "outputs": [],
   "source": [
    "reviews_processed_test = []\n",
    "unlabeled_processed_test = []\n",
    "for review_test in reviews_test:\n",
    "    review_cool_one = \"\".join(\n",
    "        [char for char in review_test if char not in digits]\n",
    "    )\n",
    "    reviews_processed_test.append(review_cool_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OwgI9Xywmg-E"
   },
   "outputs": [],
   "source": [
    "# Use PyVi for Vietnamese word tokenizer\n",
    "word_reviews_test = []\n",
    "all_words = []\n",
    "for review_test in reviews_processed_test:\n",
    "    review_test = ViTokenizer.tokenize(review_test.lower())\n",
    "    word_reviews_test.append(review_test.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p02GxCh6mg-F"
   },
   "outputs": [],
   "source": [
    "sequences_test = tokenizer.texts_to_sequences(word_reviews_test)\n",
    "data_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "labels_test = encoded_labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 534,
     "status": "ok",
     "timestamp": 1653989480441,
     "user": {
      "displayName": "Đức Nguyễn Quang",
      "userId": "15255943122151670013"
     },
     "user_tz": -420
    },
    "id": "jAqUMGInmg-F",
    "outputId": "40acf056-b9c9-42ed-c767-423cc2054383"
   },
   "outputs": [],
   "source": [
    "print(\"Shape of X train and X validation tensor:\", data_test.shape)\n",
    "print(\"Shape of label train and validation tensor:\", labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 596,
     "status": "ok",
     "timestamp": 1653989548454,
     "user": {
      "displayName": "Đức Nguyễn Quang",
      "userId": "15255943122151670013"
     },
     "user_tz": -420
    },
    "id": "LKclttiOmg-F",
    "outputId": "6abe8e2e-7ed4-439f-8899-e6b30a044758"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(data_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 355,
     "status": "ok",
     "timestamp": 1653989552805,
     "user": {
      "displayName": "Đức Nguyễn Quang",
      "userId": "15255943122151670013"
     },
     "user_tz": -420
    },
    "id": "r31_uxxgmg-G",
    "outputId": "2fb9d570-546b-4652-ca5f-5e6794fc6198"
   },
   "outputs": [],
   "source": [
    "print(\"%s: %.2f%%\" % (model.metrics_names[0], score[0] * 100))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1] * 100))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "word2vec+cnn_v3.ipynb",
   "provenance": [
    {
     "file_id": "1rFZZf9ECknkLNDv8so_kQNPhqain0RqJ",
     "timestamp": 1653989613942
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
