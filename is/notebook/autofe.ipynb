{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 0.3.2 version. Select nrows to a small number when running on huge datasets.\n",
      "output = featurewiz(dataname, target, corr_limit=0.90, verbose=2, sep=',', \n",
      "\t\theader=0, test_data='',feature_engg='', category_encoders='',\n",
      "\t\tdask_xgboost_flag=False, nrows=None, skip_sulov=False, skip_xgboost=False)\n",
      "Create new features via 'feature_engg' flag : ['interactions','groupby','target']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import featurewiz as fwiz\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv(\"../app/jobs/data/churn.txt\")\n",
    "\n",
    "# Drop duplicates\n",
    "data.drop_duplicates(subset=[\"Phone\"], inplace=True, keep=\"last\")\n",
    "data.drop(columns=[\"Phone\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featurewiz has selected 0.7 as the correlation limit. Change this limit to fit your needs...\n",
      "#### Single_Label Binary_Classification problem ####\n",
      "    Loaded train data. Shape = (4999, 20)\n",
      "    Some column names had special characters which were removed...\n",
      "#### Single_Label Binary_Classification problem ####\n",
      "No test data filename given...\n",
      "#######################################################################################\n",
      "######################## C L A S S I F Y I N G  V A R I A B L E S  ####################\n",
      "#######################################################################################\n",
      "        No variables were removed since no ID or low-information variables found in data set\n",
      "Removing 0 columns from further processing since ID or low information variables\n",
      "Adding 3 interactions between categorical_vars ['State', 'IntlPlan', 'VMailPlan']...\n",
      "    target labels need to be converted...\n",
      "Completed label encoding of target variable = Churn\n",
      "How model predictions need to be transformed for Churn:\n",
      "\t{0: 'False.', 1: 'True.'}\n",
      "    Starting feature engineering...Since no test data is given, splitting train into two...\n",
      "Source X_train shape:  (3999, 22)\n",
      "| Source X_test shape:  (1000, 22)\n",
      "##################################################\n",
      "> Start preprocessing with 22 variables\n",
      "LabelEncode all Boolean Features. Leave the rest alone\n",
      "> Generate Categorical Encoded features\n",
      " + To know more, click: https://contrib.scikit-learn.org/category_encoders/hashing.html\n",
      " + added  149  additional Features using HashingEncoder\n",
      "> Cleaned NaNs in numeric features\n",
      " + test and train have similar NaN columns\n",
      "> Generate Interactions features among Numeric variables\n",
      " + added  496  Interaction Features \n",
      "> Generate Group-by Encoded Features\n",
      " + To know more, click: https://contrib.scikit-learn.org/category_encoders/jamesstein.html\n",
      " + added  16  Group-by Encoded Features using JamesSteinEncoder\n",
      "##################################################\n",
      "> Final Number of Features:  703\n",
      "##################################################\n",
      "New X_train rows: 3999, X_test rows: 4999\n",
      "New X_train columns: 703, X_test columns: 703\n",
      "    Completed feature engineering. Shape of Train (with target) = (4999, 704)\n",
      "#######################################################################################\n",
      "#####  Searching for Uncorrelated List Of Variables (SULOV) in 703 features ############\n",
      "#######################################################################################\n",
      "    there are no null values in dataset...\n",
      "    Removing (506) highly correlated variables:\n",
      "Completed SULOV. 197 features selected\n",
      "Time taken for SULOV method = 17 seconds\n",
      "Finally 197 vars selected after SULOV\n",
      "Converting all features to numeric before sending to XGBoost...\n",
      "Since ['interactions', 'groupby'] category encoding is done, dropping original categorical vars from predictors...\n",
      "    Number of booster rounds = 100\n",
      "            Time taken for regular XGBoost feature selection = 1 seconds\n",
      "            Time taken for regular XGBoost feature selection = 1 seconds\n",
      "            Time taken for regular XGBoost feature selection = 1 seconds\n",
      "            Time taken for regular XGBoost feature selection = 0 seconds\n",
      "            Time taken for regular XGBoost feature selection = 0 seconds\n",
      "        Selected: ['HashingEncoder_col_1650', 'HashingEncoder_col_1595']\n",
      "            Time taken for regular XGBoost feature selection = 0 seconds\n",
      "    Completed XGBoost feature selection in 0 seconds\n",
      "Selected 169 important features. Too many to print...\n",
      "Total Time taken for featurewiz selection = 26 seconds\n",
      "Output contains a list of 169 important features and a train dataframe\n"
     ]
    }
   ],
   "source": [
    "outputs = fwiz.featurewiz(\n",
    "    dataname=data,\n",
    "    target=\"Churn?\",\n",
    "    corr_limit=0.70,\n",
    "    verbose=0,\n",
    "    sep=\",\",\n",
    "    header=0,\n",
    "    test_data=\"\",\n",
    "    feature_engg=[\"interactions\", \"groupby\"],\n",
    "    category_encoders=\"HashingEncoder\",\n",
    "    dask_xgboost_flag=False,\n",
    "    nrows=None,\n",
    "    skip_sulov=False,\n",
    "    skip_xgboost=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
