{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04ce4e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from pymcd.mcd import Calculate_MCD\n",
    "\n",
    "mcd_toolbox = Calculate_MCD(MCD_mode=\"dtw_sl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55bd431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_pairs(model_name: str) -> dict:\n",
    "    \"\"\"Gets audio pairs of target and converted voice.\"\"\"\n",
    "\n",
    "    target_audios = glob.glob(\"target/MGL1/*.wav\")\n",
    "    converted_audios = glob.glob(f\"{model_name}/wav/*.wav\")\n",
    "\n",
    "    pairs = defaultdict(list)\n",
    "    for target_audio in target_audios:\n",
    "        target_audio_name = target_audio.split(\"/\")[-1].replace(\".wav\", \"\")\n",
    "        for converted_audio in converted_audios:\n",
    "            converted_audio_name = converted_audio.split(\"/\")[-1].replace(\n",
    "                \".wav\", \"\"\n",
    "            )\n",
    "            if target_audio_name in converted_audio_name:\n",
    "                pairs[target_audio_name].append(converted_audio_name)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "795976e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for model_name in [\n",
    "    \"vq_wav2vec_taco2\",\n",
    "    \"pretrained_vq_wav2vec_taco2\",\n",
    "    \"wav2vec2_taco2\",\n",
    "]:\n",
    "    audio_pairs = get_audio_pairs(model_name=model_name)\n",
    "\n",
    "    model_result = {model_name: {}}\n",
    "    for target_audio in audio_pairs.keys():\n",
    "        for converted_audio in audio_pairs[target_audio]:\n",
    "            model_result[model_name][\n",
    "                converted_audio\n",
    "            ] = mcd_toolbox.calculate_mcd(\n",
    "                f\"target/MGL1/{target_audio}.wav\",\n",
    "                f\"{model_name}/wav/{converted_audio}.wav\",\n",
    "            )\n",
    "\n",
    "    result.append(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5992cd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the keys and values from the result\n",
    "keys = [list(d.keys())[0] for d in result]\n",
    "values = [list(d.values())[0] for d in result]\n",
    "\n",
    "# Creating the DataFrame\n",
    "df = pd.DataFrame(values, index=keys).round(2).transpose()\n",
    "df.to_csv(\"mcd.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
