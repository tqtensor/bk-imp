{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import pyproj\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from plotly import graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    "    StackingRegressor,\n",
    ")\n",
    "from sklearn.linear_model import Lasso, LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data(df):\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        print(80 * \"*\")\n",
    "        print(\"DIMENSION: ({}, {})\".format(df.shape[0], df.shape[1]))\n",
    "        print(80 * \"*\")\n",
    "        print(\"COLUMNS:\\n\")\n",
    "        print(df.columns.values)\n",
    "        print(80 * \"*\")\n",
    "        print(\"DATA INFO:\\n\")\n",
    "        print(df.dtypes)\n",
    "        print(80 * \"*\")\n",
    "        print(\"MISSING VALUES:\\n\")\n",
    "        print(df.isnull().sum())\n",
    "        print(80 * \"*\")\n",
    "        print(\"NUMBER OF UNIQUE VALUES:\\n\")\n",
    "        print(df.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - Get Taxi dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\n",
    "    \"nyc-dataset/data/dataset.parquet\",\n",
    "    engine=\"pyarrow\",\n",
    ")\n",
    "df.dropna(inplace=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Time series model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sarimax = df.copy()\n",
    "df_sarimax = df_sarimax[df_sarimax[\"location_id\"] == 132]\n",
    "train, test = train_test_split(df_sarimax, shuffle=False, test_size=0.2)\n",
    "\n",
    "# Try sarimax model with different parameters, use only which has lowest aic\n",
    "\n",
    "\n",
    "def get_sarima_params(data, train_exog):\n",
    "    p = d = q = range(0, 2)\n",
    "    pdq = list(itertools.product(p, d, q))\n",
    "    seasonal_pdq = [\n",
    "        (x[0], x[1], x[2], 7) for x in list(itertools.product(p, d, q))\n",
    "    ]\n",
    "    result_list = []\n",
    "\n",
    "    for param in pdq:\n",
    "        for param_seasonal in seasonal_pdq:\n",
    "            try:\n",
    "                mod = sm.tsa.statespace.SARIMAX(\n",
    "                    data,\n",
    "                    exog=train_exog,\n",
    "                    order=param,\n",
    "                    seasonal_order=param_seasonal,\n",
    "                    enforce_stationarity=False,\n",
    "                    enforce_invertibility=True,\n",
    "                )\n",
    "                results = mod.fit(maxiter=2000)\n",
    "                result_list.append(\n",
    "                    {\n",
    "                        \"pda\": param,\n",
    "                        \"seasonal_pda\": param_seasonal,\n",
    "                        \"aic\": results.aic,\n",
    "                    }\n",
    "                )\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "\n",
    "    if not result_list:\n",
    "        raise ValueError(\"No valid SARIMA parameters found.\")\n",
    "\n",
    "    result_table = pd.DataFrame(result_list)\n",
    "    optimal_params = result_table[\n",
    "        result_table[\"aic\"] == result_table.aic.min()\n",
    "    ]\n",
    "    order = optimal_params.pda.values[0]\n",
    "    seasonal_order = optimal_params.seasonal_pda.values[0]\n",
    "    return (order, seasonal_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "def apply_sarimax(\n",
    "    train_data, train_exog, test_data, test_exog, order, seasonal_order\n",
    "):\n",
    "    print(\"SARIMAX MODEL ORDERS ARE = {} {} \".format(order, seasonal_order))\n",
    "\n",
    "    mod = sm.tsa.statespace.SARIMAX(\n",
    "        train_data, exog=train_exog, order=order, seasonal_order=seasonal_order\n",
    "    )\n",
    "    results = mod.fit()\n",
    "\n",
    "    pred = results.get_prediction(\n",
    "        start=train_data.index[0],\n",
    "        end=train_data.index[-1],\n",
    "        exog=train_exog,\n",
    "        dynamic=False,\n",
    "    )\n",
    "    train_forecast = pred.predicted_mean.round()\n",
    "    train_forecast[train_forecast < 0] = 0\n",
    "\n",
    "    pred1 = results.get_prediction(\n",
    "        start=test_data.index[0],\n",
    "        end=test_data.index[-1],\n",
    "        exog=test_exog,\n",
    "        dynamic=False,\n",
    "    )\n",
    "    test_forecast = pred1.predicted_mean.round()\n",
    "    test_forecast[test_forecast < 0] = 0\n",
    "    return (train_forecast, test_forecast)\n",
    "\n",
    "\n",
    "def print_sarima_results(train_data, test_data, train_forecast, test_forecast):\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.plot(train_data.index, train_data, label=\"Train\")\n",
    "    plt.plot(test_data.index, test_data, label=\"Test\")\n",
    "    plt.plot(train_forecast.index, train_forecast, label=\"Train Forecast\")\n",
    "    plt.plot(test_forecast.index, test_forecast, label=\"Test Forecast\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    train_actual = np.asarray(train_data)\n",
    "    train_forecast = np.asarray(train_forecast)\n",
    "    test_actual = np.asarray(test_data)\n",
    "    test_forecast = np.asarray(test_forecast)\n",
    "    # Find mape\n",
    "    train_ape = np.abs((train_actual - train_forecast) / train_actual)\n",
    "    test_ape = np.abs((test_actual - test_forecast) / test_actual)\n",
    "    train_mape = np.mean(train_ape) * 100\n",
    "    test_mape = np.mean(test_ape) * 100\n",
    "\n",
    "    # Find rmsle\n",
    "    train_log_actual = np.log1p(train_actual)\n",
    "    train_log_forecast = np.log1p(train_forecast)\n",
    "\n",
    "    test_log_actual = np.log1p(test_actual)\n",
    "    test_log_forecast = np.log1p(test_forecast)\n",
    "\n",
    "    train_square_diff = (train_log_actual - train_log_forecast) ** 2\n",
    "    test_square_diff = (test_log_actual - test_log_forecast) ** 2\n",
    "\n",
    "    train_mean_squared_diff = np.mean(train_square_diff)\n",
    "    test_mean_squared_diff = np.mean(test_square_diff)\n",
    "\n",
    "    train_rmsle = np.sqrt(train_mean_squared_diff)\n",
    "    test_rmsle = np.sqrt(test_mean_squared_diff)\n",
    "\n",
    "    print(\n",
    "        \"Train Mean Absolute Error:     \",\n",
    "        mean_absolute_error(train_data, train_forecast),\n",
    "    )\n",
    "    print(\n",
    "        \"Train Root Mean Squared Error: \",\n",
    "        np.sqrt(mean_squared_error(train_data, train_forecast)),\n",
    "    )\n",
    "    print(\"Train Mean Absolute Percentage Error:     \", train_mape)\n",
    "    print(\"Train Root Mean Squared Log Error:        \", train_rmsle)\n",
    "    print(\n",
    "        \"Test Mean Absolute Error:      \",\n",
    "        mean_absolute_error(test_data, test_forecast),\n",
    "    )\n",
    "    print(\n",
    "        \"Test Root Mean Squared Error:  \",\n",
    "        np.sqrt(mean_squared_error(test_data, test_forecast)),\n",
    "    )\n",
    "    print(\"Test Mean Absolute Percentage Error:     \", test_mape)\n",
    "    print(\"Test Root Mean Squared Log Error:        \", test_rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train[\"trip_count\"].reset_index(drop=True)\n",
    "\n",
    "train_exog = train.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"temperature_2m_max\",\n",
    "        \"temperature_2m_min\",\n",
    "        \"temperature_2m_mean\",\n",
    "        \"precipitation_sum\",\n",
    "        \"rain_sum\",\n",
    "    ],\n",
    "].reset_index(drop=True)\n",
    "\n",
    "test_data = test[\"trip_count\"].reset_index(drop=True)\n",
    "test_exog = test.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"temperature_2m_max\",\n",
    "        \"temperature_2m_min\",\n",
    "        \"temperature_2m_mean\",\n",
    "        \"precipitation_sum\",\n",
    "        \"rain_sum\",\n",
    "    ],\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order, seasonal_order = get_sarima_params(train_data, train_exog)\n",
    "train_forecast, test_forecast = apply_sarimax(\n",
    "    train_data, train_exog, test_data, test_exog, order, seasonal_order\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sarima_results(train_data, test_data, train_forecast, test_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_reg = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_reg[\"location_id\"] = [\n",
    "    \"location_id_\" + str(int(x)).zfill(4)\n",
    "    for x in df_for_reg[\"location_id\"].values\n",
    "]\n",
    "df_for_reg[\"weathercode\"] = [\n",
    "    \"weather_code_\" + str(int(x)).zfill(4)\n",
    "    for x in df_for_reg[\"weathercode\"].values\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_reg[\"day_of_year\"] = df_for_reg[\"tpep_pickup_hour\"].dt.dayofyear\n",
    "df_for_reg[\"day_of_month\"] = df_for_reg[\"tpep_pickup_hour\"].dt.day\n",
    "df_for_reg[\"day_of_week\"] = df_for_reg[\"tpep_pickup_hour\"].dt.dayofweek\n",
    "df_for_reg[\"is_weekend\"] = [\n",
    "    1 if x in [5, 6] else 0 for x in df_for_reg[\"day_of_week\"].values\n",
    "]\n",
    "df_for_reg[\"year\"] = df_for_reg[\"tpep_pickup_hour\"].dt.year\n",
    "df_for_reg[\"month\"] = df_for_reg[\"tpep_pickup_hour\"].dt.month\n",
    "df_for_reg[\"hour\"] = df_for_reg[\"tpep_pickup_hour\"].dt.hour\n",
    "\n",
    "\n",
    "# Sort the data by day of the year in ascending order\n",
    "df_for_reg = df_for_reg.sort_values(by=[\"tpep_pickup_hour\"])\n",
    "\n",
    "# Drop datetime column\n",
    "df_for_reg = df_for_reg.drop([\"time\", \"tpep_pickup_hour\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_reg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.1 - Create sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_window(df, window_size):\n",
    "    # Sort the data by location_id and day_of_year to ensure chronological order within each group\n",
    "    tmp_data = df.copy()\n",
    "    tmp_data = tmp_data.sort_values([\"location_id\", \"day_of_year\"])\n",
    "\n",
    "    # Apply sliding window to create new columns within each group\n",
    "    grouped = tmp_data.groupby(\"location_id\")\n",
    "    for i in range(1, window_size + 1):\n",
    "        col_name = f\"trip_count_day_backward_{i}\"\n",
    "        tmp_data[col_name] = grouped[\"trip_count\"].shift(i)\n",
    "\n",
    "    # Remove the first rows within each group that contain NaN values due to shifting\n",
    "    tmp_data = (\n",
    "        tmp_data.groupby(\"location_id\")\n",
    "        .apply(lambda x: x.iloc[window_size:])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return tmp_data\n",
    "\n",
    "\n",
    "df_for_reg = create_sliding_window(df_for_reg, 7)\n",
    "df_for_reg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_for_reg[\"trip_count\"]\n",
    "X_cat = df_for_reg.drop([\"trip_count\"], axis=1)\n",
    "X_num = pd.get_dummies(X_cat, drop_first=True)\n",
    "X_train_cat, X_test_cat, y_train, y_test = train_test_split(\n",
    "    X_cat, y, test_size=0.2, shuffle=False\n",
    ")\n",
    "X_train_num, X_test_num, y_train, y_test = train_test_split(\n",
    "    X_num, y, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "# Store the splitted data\n",
    "if not os.path.exists(\"data/processed\"):\n",
    "    os.makedirs(\"data/processed\")\n",
    "with open(\"data/processed/cat.pkl\", \"wb\") as f:\n",
    "    pickle.dump((X_train_cat, X_test_cat, y_train, y_test), f)\n",
    "with open(\"data/processed/num.pkl\", \"wb\") as f:\n",
    "    pickle.dump((X_train_num, X_test_num, y_train, y_test), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the regressors\n",
    "regressors = {\n",
    "    \"CatBoost\": CatBoostRegressor(\n",
    "        cat_features=[\"location_id\", \"weathercode\"],\n",
    "        iterations=1000,\n",
    "        learning_rate=0.1,\n",
    "        verbose=0,\n",
    "    ),\n",
    "    \"XGBRegressor\": XGBRegressor(),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(n_estimators=20, n_jobs=-1),\n",
    "}\n",
    "\n",
    "# Create the pipelines\n",
    "pipelines = []\n",
    "for regressor_name, regressor in regressors.items():\n",
    "    pipeline = Pipeline([(regressor_name, regressor)])\n",
    "    pipelines.append(pipeline)\n",
    "\n",
    "# Train and evaluate the pipelines\n",
    "results = []\n",
    "for idx, pipeline in enumerate(pipelines):\n",
    "    regressor_name = \"_\".join(list(pipeline.named_steps.keys()))\n",
    "    print(f\"Training and evaluating Pipeline {idx+1}: {regressor_name}...\")\n",
    "\n",
    "    if regressor_name == \"CatBoost\":\n",
    "        # Fit the pipeline to the training data\n",
    "        pipeline.fit(X_train_cat, y_train)\n",
    "\n",
    "        # Make predictions on the train and test data\n",
    "        train_pred = pipeline.predict(X_train_cat)\n",
    "        test_pred = pipeline.predict(X_test_cat)\n",
    "    else:\n",
    "        # Fit the pipeline to the training data\n",
    "        pipeline.fit(X_train_num, y_train)\n",
    "\n",
    "        # Store the pipeline\n",
    "        if not os.path.exists(\"data/models\"):\n",
    "            os.makedirs(\"data/models\")\n",
    "        with open(f\"data/models/{regressor_name}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(pipeline, f)\n",
    "\n",
    "        # Make predictions on the train and test data\n",
    "        train_pred = pipeline.predict(X_train_num)\n",
    "        test_pred = pipeline.predict(X_test_num)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    train_mae = mean_absolute_error(y_train, train_pred)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
    "    train_ape = np.abs((y_train - train_pred) / y_train)\n",
    "    train_mape = np.mean(train_ape) * 100\n",
    "\n",
    "    test_mae = mean_absolute_error(y_test, test_pred)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))\n",
    "    test_ape = np.abs((y_test - test_pred) / y_test)\n",
    "    test_mape = np.mean(test_ape) * 100\n",
    "\n",
    "    # Calculate RMSLE\n",
    "    train_rmsle = np.sqrt(\n",
    "        np.mean((np.log1p(y_train) - np.log1p(train_pred)) ** 2)\n",
    "    )\n",
    "    test_rmsle = np.sqrt(\n",
    "        np.mean((np.log1p(y_test) - np.log1p(test_pred)) ** 2)\n",
    "    )\n",
    "\n",
    "    # Store the results\n",
    "    results.append(\n",
    "        {\n",
    "            \"Pipeline\": regressor_name,\n",
    "            \"Train MAE\": train_mae,\n",
    "            \"Train RMSE\": train_rmse,\n",
    "            \"Train MAPE\": train_mape,\n",
    "            \"Train RMSLE\": train_rmsle,\n",
    "            \"Test MAE\": test_mae,\n",
    "            \"Test RMSE\": test_rmse,\n",
    "            \"Test MAPE\": test_mape,\n",
    "            \"Test RMSLE\": test_rmsle,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Display the results\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hungdo_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
