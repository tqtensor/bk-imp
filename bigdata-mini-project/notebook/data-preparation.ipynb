{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c492a488-88e7-4375-a3ba-c04ac1a1674d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (approx_count_distinct, avg, col, count,\n",
    "                                   desc, explode, from_unixtime, lit, size)\n",
    "from pyspark.sql.types import (FloatType, IntegerType, StringType, StructField,\n",
    "                               StructType)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6759a0c0-b53d-402c-aeda-0b5f6cc6a0c5",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7644715d-ce5b-41b2-bac7-cd0a5d9335fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Getting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e47e3a-757c-49ff-b030-74fa743dd420",
   "metadata": {},
   "source": [
    "The Amazon dataset from https://jmcauley.ucsd.edu/data/amazon_v2 is a comprehensive collection of product reviews and metadata. It is categorized into various domains, such as electronics, books, clothing, and more. I have created a script that allows users to download specific categories by inputting the correct category name. This simplifies accessing targeted subsets of the dataset for research purposes.\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "# Set the directory where the JSON files should be stored\n",
    "DATA_DIR=\"bigdata-mini-project/data/\"\n",
    "\n",
    "# Prompt the user for the dataset name\n",
    "read -p \"Enter the name of the Amazon review dataset to download (e.g., Digital_Music): \" DATASET_NAME\n",
    "\n",
    "# Check if the JSON file for the specified dataset exists in the data directory\n",
    "if [ ! -f \"${DATA_DIR}${DATASET_NAME}.json\" ]; then\n",
    "\n",
    "  # If the file does not exist, download it from the first link\n",
    "  echo \"Downloading ${DATASET_NAME}.json file...\"\n",
    "  wget --no-check-certificate -P \"${DATA_DIR}\" \"https://jmcauley.ucsd.edu/data/amazon_v2/categoryFiles/${DATASET_NAME}.json.gz\"\n",
    "\n",
    "  # Extract the downloaded file\n",
    "  echo \"Extracting ${DATASET_NAME}.json file...\"\n",
    "  gunzip \"${DATA_DIR}${DATASET_NAME}.json.gz\"\n",
    "\n",
    "fi\n",
    "\n",
    "# Check if the meta JSON file for the specified dataset exists in the data directory\n",
    "if [ ! -f \"${DATA_DIR}meta_${DATASET_NAME}.json\" ]; then\n",
    "\n",
    "  # If the file does not exist, download it from the second link\n",
    "  echo \"Downloading meta_${DATASET_NAME}.json file...\"\n",
    "  wget --no-check-certificate -P \"${DATA_DIR}\" \"https://jmcauley.ucsd.edu/data/amazon_v2/metaFiles2/meta_${DATASET_NAME}.json.gz\"\n",
    "\n",
    "  # Extract the downloaded file\n",
    "  echo \"Extracting meta_${DATASET_NAME}.json file...\"\n",
    "  gunzip \"${DATA_DIR}meta_${DATASET_NAME}.json.gz\"\n",
    "\n",
    "fi\n",
    "\n",
    "echo \"Done.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d3a1bf-a310-4c27-b01a-387882500f9c",
   "metadata": {},
   "source": [
    "## Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49311e41-8701-40f8-8d8d-54d278b790b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/15 05:08:52 WARN Utils: Your hostname, workspace resolves to a loopback address: 127.0.1.1; using 11.11.1.73 instead (on interface eth0)\n",
      "23/05/15 05:08:52 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/terrabot/bk-imp/.venv/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/terrabot/.ivy2/cache\n",
      "The jars for the packages stored in: /home/terrabot/.ivy2/jars\n",
      "org.neo4j#neo4j-connector-apache-spark_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-ca642d0a-4baf-4bbf-b3cd-c7111fb616ae;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.neo4j#neo4j-connector-apache-spark_2.12;5.0.1_for_spark_3 in central\n",
      "\tfound org.neo4j#neo4j-connector-apache-spark_2.12_common;5.0.1 in central\n",
      "\tfound org.neo4j.driver#neo4j-java-driver;4.4.11 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.4 in central\n",
      "\tfound org.apache.xbean#xbean-asm6-shaded;4.10 in central\n",
      "\tfound org.neo4j#neo4j-cypher-dsl;2020.1.4 in central\n",
      "\tfound org.apiguardian#apiguardian-api;1.1.0 in central\n",
      ":: resolution report :: resolve 294ms :: artifacts dl 11ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.xbean#xbean-asm6-shaded;4.10 from central in [default]\n",
      "\torg.apiguardian#apiguardian-api;1.1.0 from central in [default]\n",
      "\torg.neo4j#neo4j-connector-apache-spark_2.12;5.0.1_for_spark_3 from central in [default]\n",
      "\torg.neo4j#neo4j-connector-apache-spark_2.12_common;5.0.1 from central in [default]\n",
      "\torg.neo4j#neo4j-cypher-dsl;2020.1.4 from central in [default]\n",
      "\torg.neo4j.driver#neo4j-java-driver;4.4.11 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.4 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   7   |   0   |   0   |   0   ||   7   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-ca642d0a-4baf-4bbf-b3cd-c7111fb616ae\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 7 already retrieved (0kB/6ms)\n",
      "23/05/15 05:08:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"bk-imp\")\n",
    "    .config(\"spark.executor.memory\", \"16g\")\n",
    "    .config(\"spark.executor.cores\", \"2\")\n",
    "    .config(\"spark.executor.instances\", \"5\")\n",
    "    .config(\n",
    "        \"spark.jars.packages\",\n",
    "        \"org.neo4j:neo4j-connector-apache-spark_2.12:5.0.1_for_spark_3\",\n",
    "    )\n",
    "    .getOrCreate()\n",
    ")  # this spark session can connect to Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f35e563c-a025-4195-870a-1d3965627aee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Sample the JSON file\n",
    "sample_df = spark.read.json(\"../data/Automotive.json\", samplingRatio=0.001)\n",
    "\n",
    "# Get the schema from the sampled data\n",
    "schema = sample_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d6fa454-6d50-4066-96a7-616371fb0d24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the entire JSON file using the inferred schema\n",
    "review_df = (\n",
    "    spark.read.json(\"../data/Automotive.json\", schema=schema)\n",
    "    .dropDuplicates()\n",
    "    .repartition(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f02dabf4-9846-4d95-a007-4a0bb21047f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:=======================================================> (28 + 1) / 29]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " asin           | B014GM6FX8                                                                                                                                                                                                                                                                           \n",
      " image          | null                                                                                                                                                                                                                                                                                 \n",
      " overall        | 5.0                                                                                                                                                                                                                                                                                  \n",
      " reviewText     | Works great! I bolted it on to the front of my boat and it endures runnig over saw grass, trees, and landing on the bank. It has also been covered in water and still functions like I just pulled it out of the box. The light bar does a great job of lighting up the whole river. \n",
      " reviewTime     | 01 21, 2016                                                                                                                                                                                                                                                                          \n",
      " reviewerID     | A2YLQZHD6U31U0                                                                                                                                                                                                                                                                       \n",
      " reviewerName   | Amazon Customer                                                                                                                                                                                                                                                                      \n",
      " style          | {null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null,  20\" 126W, null, null}                                                                                                                                                              \n",
      " summary        | Works great! I bolted it on to the front of ...                                                                                                                                                                                                                                      \n",
      " unixReviewTime | 1453334400                                                                                                                                                                                                                                                                           \n",
      " verified       | true                                                                                                                                                                                                                                                                                 \n",
      " vote           | null                                                                                                                                                                                                                                                                                 \n",
      "-RECORD 1----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " asin           | B00GI77WSW                                                                                                                                                                                                                                                                           \n",
      " image          | null                                                                                                                                                                                                                                                                                 \n",
      " overall        | 3.0                                                                                                                                                                                                                                                                                  \n",
      " reviewText     | Bright, sharp, would not fit deep enough into the light sockets on my 2004 Colorado                                                                                                                                                                                                  \n",
      " reviewTime     | 01 16, 2016                                                                                                                                                                                                                                                                          \n",
      " reviewerID     | A1HA6IUT9GMXK7                                                                                                                                                                                                                                                                       \n",
      " reviewerName   | Jesse Packard                                                                                                                                                                                                                                                                        \n",
      " style          | null                                                                                                                                                                                                                                                                                 \n",
      " summary        | Ok if they fit                                                                                                                                                                                                                                                                       \n",
      " unixReviewTime | 1452902400                                                                                                                                                                                                                                                                           \n",
      " verified       | true                                                                                                                                                                                                                                                                                 \n",
      " vote           | null                                                                                                                                                                                                                                                                                 \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "review_df.show(2, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3905bff0-5537-497a-baf7-791be2597de5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rename the columns to snake style\n",
    "review_df = (\n",
    "    review_df.withColumnRenamed(\"reviewerID\", \"reviewer_id\")\n",
    "    .withColumnRenamed(\"reviewerName\", \"reviewer_name\")\n",
    "    .withColumnRenamed(\"overall\", \"rating\")\n",
    "    .withColumnRenamed(\"reviewText\", \"review_text\")\n",
    "    .withColumnRenamed(\"summary\", \"review_summary\")\n",
    "    .withColumnRenamed(\"unixReviewTime\", \"unix_review_time\")\n",
    "    .withColumnRenamed(\"reviewTime\", \"review_time\")\n",
    "    .withColumnRenamed(\"style\", \"style_name\")\n",
    "    .withColumnRenamed(\"asin\", \"product_id\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7804442a-d02e-4f0a-9d9e-dc5179b32155",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset:\n",
      "product_id\n",
      "image\n",
      "rating\n",
      "review_text\n",
      "review_time\n",
      "reviewer_id\n",
      "reviewer_name\n",
      "style_name\n",
      "review_summary\n",
      "unix_review_time\n",
      "verified\n",
      "vote\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:===================================================>     (26 + 3) / 29]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of rows in the dataset: 7828023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Print the list of columns\n",
    "print(\"Columns in the dataset:\")\n",
    "for col_name in review_df.columns:\n",
    "    print(col_name)\n",
    "\n",
    "# Print the number of rows\n",
    "print(f\"\\nNumber of rows in the dataset: {review_df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ca80c0-37a9-45a3-80e2-7dca9c436424",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b39f8b5-8e1e-499a-beba-911a2272b700",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/15 05:10:06 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 39:======================================================> (28 + 1) / 29]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique reviewers         : 4079467\n",
      "Number of unique reviewed products : 926020\n",
      "Number of total reviews            : 7828023\n",
      "Average number of reviews per user : 1.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count the number of distinct reviewers, reviewed products, and total reviews\n",
    "num_distinct_reviewers = review_df.agg(\n",
    "    approx_count_distinct(\"reviewer_id\")\n",
    ").collect()[0][0]\n",
    "num_distinct_products = review_df.agg(\n",
    "    approx_count_distinct(\"product_id\")\n",
    ").collect()[0][0]\n",
    "num_total_reviews = review_df.count()\n",
    "\n",
    "# Calculate the average number of reviews per user\n",
    "avg_reviews_per_user = num_total_reviews / num_distinct_reviewers\n",
    "\n",
    "# Print the statistics\n",
    "print(f\"Number of unique reviewers         : {num_distinct_reviewers}\")\n",
    "print(f\"Number of unique reviewed products : {num_distinct_products}\")\n",
    "print(f\"Number of total reviews            : {num_total_reviews}\")\n",
    "print(f\"Average number of reviews per user : {avg_reviews_per_user:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08536efa-cde9-4ed6-b61f-cae755cd60ef",
   "metadata": {},
   "source": [
    "### Data Types Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cf99362-fc6d-4d13-9eb1-993c53a81911",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "review_df = review_df.withColumn(\n",
    "    \"reviewTime_date\", from_unixtime(\"unix_review_time\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a4547e-263f-454d-8154-3f925f6a9770",
   "metadata": {},
   "source": [
    "### Sampling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d01c1a1-8183-4993-a477-c9bd34f8b69b",
   "metadata": {},
   "source": [
    "+ Take top 10k popular items\n",
    "+ Take 50k popular reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11e8e6da-d5e2-4059-9018-d9c7d9e8b549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sort by the count of reviews in descending order and take the top 10k reviewers\n",
    "top_reviewers_df = (\n",
    "    review_df.repartition(10)\n",
    "    .groupBy(\"reviewer_id\")\n",
    "    .count()\n",
    "    .orderBy(desc(\"count\"))\n",
    "    .limit(10000)\n",
    ")\n",
    "\n",
    "# sort by the count of reviews in descending order and take the top 50k products\n",
    "top_products_df = (\n",
    "    review_df.repartition(10)\n",
    "    .groupBy(\"product_id\")\n",
    "    .count()\n",
    "    .orderBy(desc(\"count\"))\n",
    "    .limit(50000)\n",
    ")\n",
    "\n",
    "sampled_review_df = (\n",
    "    review_df.repartition(10)\n",
    "    .join(top_reviewers_df, \"reviewer_id\", \"inner\")\n",
    "    .join(top_products_df, \"product_id\", \"inner\")\n",
    "    .drop(\"count\")\n",
    "    .dropDuplicates([\"product_id\", \"reviewer_id\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79c9d5c5-767f-4da7-896e-b6e72bf9935f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/15 05:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:12:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:12:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:12:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:12:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:12:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:12:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:12:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:12:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:12:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:12:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:12:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:12:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:12:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:12:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:12:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:12:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:13:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:13:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:13:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:13:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:13:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:13:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:13:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:13:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:13:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:13:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:13:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:13:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:13:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:13:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:13:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:13:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:13:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:15:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:15:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:15:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:15:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:15:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:15:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:15:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:15:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:15:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:15:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:15:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:15:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:15:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:15:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:15:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/05/15 05:15:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 170:======================>                                 (4 + 6) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique reviewers         : 8956\n",
      "Number of unique reviewed products : 40021\n",
      "Number of total reviews            : 225761\n",
      "Average number of reviews per user : 25.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count the number of distinct reviewers, reviewed products, and total reviews\n",
    "num_distinct_reviewers = sampled_review_df.agg(\n",
    "    approx_count_distinct(\"reviewer_id\")\n",
    ").collect()[0][0]\n",
    "num_distinct_products = sampled_review_df.agg(\n",
    "    approx_count_distinct(\"product_id\")\n",
    ").collect()[0][0]\n",
    "num_total_reviews = sampled_review_df.count()\n",
    "\n",
    "# Calculate the average number of reviews per user\n",
    "avg_reviews_per_user = num_total_reviews / num_distinct_reviewers\n",
    "\n",
    "# Print the statistics\n",
    "print(f\"Number of unique reviewers         : {num_distinct_reviewers}\")\n",
    "print(f\"Number of unique reviewed products : {num_distinct_products}\")\n",
    "print(f\"Number of total reviews            : {num_total_reviews}\")\n",
    "print(f\"Average number of reviews per user : {avg_reviews_per_user:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c43ca6-34e3-4f60-b5cf-a4ade9514265",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampled_review_df.write.parquet(\"../data/sampled_review_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc82b50-f853-4bf2-bb92-6e5249394c7f",
   "metadata": {},
   "source": [
    "# Graph Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c02e797-2912-453e-a298-6510f204a475",
   "metadata": {},
   "source": [
    "By running the command `docker-compose up -d` in the directory `bigdata-mini-project/docker/neo4j/` on a machine with Docker installed, we can start a Neo4j database instance in a Docker container. This will create a container based on the configuration in the `docker-compose.yml` file located in that directory.\n",
    "\n",
    "The address of the Neo4j database has been mapped to http://remote.tqtensor.com:4747."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3486e1-a13f-498e-a4f4-dd40f1b8dbb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = sampled_review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a623e7-69c5-48d3-88e0-7957c54dd259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write nodes to Neo4j for products\n",
    "df.select(col(\"product_id\").alias(\"id\")).dropDuplicates().repartition(\n",
    "    8\n",
    ").write.format(\"org.neo4j.spark.DataSource\").option(\n",
    "    \"url\", \"bolt://remote.tqtensor.com:7687\"\n",
    ").option(\n",
    "    \"node.keys\", \"id\"\n",
    ").option(\n",
    "    \"labels\", \":Product\"\n",
    ").mode(\n",
    "    \"overwrite\"\n",
    ").save()\n",
    "\n",
    "# Write nodes to Neo4j for reviewers\n",
    "df.select(col(\"reviewer_id\").alias(\"id\")).dropDuplicates().repartition(\n",
    "    8\n",
    ").write.format(\"org.neo4j.spark.DataSource\").option(\n",
    "    \"url\", \"bolt://remote.tqtensor.com:7687\"\n",
    ").option(\n",
    "    \"node.keys\", \"id\"\n",
    ").option(\n",
    "    \"labels\", \":User\"\n",
    ").mode(\n",
    "    \"overwrite\"\n",
    ").save()\n",
    "\n",
    "# Write relationships to Neo4j between reviewers and products\n",
    "df.repartition(8).write.format(\"org.neo4j.spark.DataSource\").option(\n",
    "    \"url\", \"bolt://remote.tqtensor.com:7687\"\n",
    ").option(\"relationship.save.strategy\", \"keys\").option(\n",
    "    \"relationship\", \"reviews\"\n",
    ").option(\n",
    "    \"relationship.properties\", \"rating\"\n",
    ").option(\n",
    "    \"relationship.source.labels\", \":User\"\n",
    ").option(\n",
    "    \"relationship.source.node.keys\", \"reviewer_id:id\"\n",
    ").option(\n",
    "    \"relationship.target.labels\", \":Product\"\n",
    ").option(\n",
    "    \"relationship.target.node.keys\", \"product_id:id\"\n",
    ").mode(\n",
    "    \"overwrite\"\n",
    ").save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
